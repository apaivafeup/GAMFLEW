TY  - CONF
TI  - Development of Learning Media to Introduce Traditional Musical Instruments using Augmented Reality on Instagram
T2  - 2021 International Conference on Computer Science and Engineering (IC2SE)
SP  - 1
EP  - 5
AU  - A. N. Baiti
AU  - H. Dwi Hermawan
AU  - A. Saputri
PY  - 2021
DO  - 10.1109/IC2SE52832.2021.9791894
JO  - 2021 International Conference on Computer Science and Engineering (IC2SE)
IS  - 
SN  - 
VO  - 1
VL  - 1
JA  - 2021 International Conference on Computer Science and Engineering (IC2SE)
Y1  - 16-16 Nov. 2021
AB  - Along with the times, the concern for the preservation of Indonesian culture has become very minimal. Many people prefer to play modern musical instruments over traditional musical instruments. The lack of introduction and socialization of Indonesian culture is also one of the important factors why people are less interested in traditional musical instruments. This study aims to develop learning media for the introduction of traditional musical instruments through Instagram. The method used in this research is Research and Development. The first stage is needs analysis and literature study. The second stage is to design media using use cases. The third stage is the implementation or creation of Instagram filter learning media and testing of functionality and compatibility tests by media experts. The fourth stage is the software testing stage which includes 2 stages of testing, namely verification and validation testing and knowing the quality and feasibility. The results of the analysis show that the Instagram filter learning media is feasible to use. However, this research still needs further research for the development of better media.
ER  - 

TY  - CONF
TI  - A Test Architecture for Machine Learning Product
T2  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 273
EP  - 278
AU  - Y. Nishi
AU  - S. Masuda
AU  - H. Ogawa
AU  - K. Uetsuki
PY  - 2018
DO  - 10.1109/ICSTW.2018.00060
JO  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 9-13 April 2018
AB  - As machine learning (ML) technology continues to spread by rapid evolution, the system or service using Machine Learning technology, called ML product, makes big impact on our life, society and economy. Meanwhile, Quality Assurance (QA) for ML product is quite more difficult than hardware, non-ML software and service because performance of ML technology is much better than non-ML technology in exchange for the characteristics of ML product, e.g. low explainability. We must keep rapid evolution and reduce quality risk of ML product simultaneously. In this paper, we show a Quality Assurance Framework for Machine Learning product. Scope of QA in this paper is limited to product evaluation. First, a policy of QA for ML Product is proposed. General principles of product evaluation is introduced and applied to ML product evaluation as a part of the policy. They are composed of A-ARAI: Allowability, Achievability, Robustness, Avoidability and Improvability. A strategy of ML Product Evaluation is constructed as another part of the policy. Quality Integrity Level for ML product is also modelled. Second, we propose a test architecture of ML product testing. It consists of test levels and fundamental test types of ML product testing, including snapshot testing, learning testing and confrontation testing. Finally, we defines QA activity levels for ML product.
ER  - 

TY  - CONF
TI  - To Seed or Not to Seed? An Empirical Analysis of Usage of Seeds for Testing in Machine Learning Projects
T2  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 151
EP  - 161
AU  - S. Dutta
AU  - A. Arunachalam
AU  - S. Misailovic
PY  - 2022
DO  - 10.1109/ICST53961.2022.00026
JO  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 4-14 April 2022
AB  - Many Machine Learning (ML) algorithms are in-herently random in nature - executing them using the same inputs may lead to slightly different results across different runs. Such randomness makes it challenging for developers to write tests for their implementations of ML algorithms. A natural consequence of randomness is test flakiness - tests both pass and fail non-deterministically for same version of code. Developers often choose to alleviate test flakiness in ML projects by setting seeds in the random number generators used by the code under test. However, this approach commonly serves as a “workaround” rather than an actual solution. Instead, it may be possible to mitigate flakiness and alleviate the negative effects of setting seeds using alternative approaches. To understand the role of seeds and the feasibility of alternative solutions, we conduct the first large-scale empirical study of the usage of seeds and its implications on testing on a corpus of 114 Machine Learning projects. We identify 461 tests in these projects that fail without seeds and study their nature and root causes. We try to minimize the flakiness of a subset of 42 identified tests using alternative strategies such as tuning algorithm hyper-parameters and adjusting assertion bounds and send them to developers. So far, developers have accepted our fixes for 26 tests. We further manually analyze a subset of 56 tests and study various characteristics such as the nature of test oracles and how the seed settings evolve over time. Finally, we provide a general set of recommendations for both researchers and developers in the context of setting seeds in tests.
ER  - 

TY  - CONF
TI  - Learning-Based Self-Adaptive Assurance of Timing Properties in a Real-Time Embedded System
T2  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 77
EP  - 80
AU  - M. Helali Moghadam
AU  - M. Saadatmand
AU  - M. Borg
AU  - M. Bohlin
AU  - B. Lisper
PY  - 2018
DO  - 10.1109/ICSTW.2018.00031
JO  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 9-13 April 2018
AB  - Providing an adaptive runtime assurance technique to meet the performance requirements of a real-time system without the need for a precise model could be a challenge. Adaptive performance assurance based on monitoring the status of timing properties can bring more robustness to the underlying platform. At the same time, the results or the achieved policy of this adaptive procedure could be used as feedback to update the initial model, and consequently for producing proper test cases. Reinforcement-learning has been considered as a promising adaptive technique for assuring the satisfaction of the performance properties of software-intensive systems in recent years. In this work-in-progress paper, we propose an adaptive runtime timing assurance procedure based on reinforcement learning to satisfy the performance requirements in terms of response time. The timing control problem is formulated as a Markov Decision Process and the details of applying the proposed learning-based timing assurance technique are described.
ER  - 

TY  - CONF
TI  - gDefects4DL: A Dataset of General Real-World Deep Learning Program Defects
T2  - 2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
SP  - 90
EP  - 94
AU  - Y. Liang
AU  - Y. Lin
AU  - X. Song
AU  - J. Sun
AU  - Z. Feng
AU  - J. S. Dong
PY  - 2022
DO  - 10.1145/3510454.3516826
JO  - 2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
IS  - 
SN  - 2574-1926
VO  - 
VL  - 
JA  - 2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
Y1  - 22-24 May 2022
AB  - The development of deep learning programs, as a new programming paradigm, is observed to suffer from various defects. Emerging research works have been proposed to detect, debug, and repair deep learning bugs, which drive the need to construct the bug benchmarks. In this work, we present gDefects4DL, a dataset for general bugs of deep learning programs. Comparing to existing datasets, gDefects4DL collects bugs where the root causes and fix solutions can be well generalized to other projects. Our general bugs include deep learning program bugs such as (1) violation of deep learning API usage pattern (e.g., the standard to implement cross entropy function y•log(y), y → 0, without NaN error), (2) shape-mismatch of tensor calculation, (3) numeric bugs, (4) type-mismatch (e.g., confusing similar types among numpy, pytorch, and tensorflow), (5) violation of model architecture design convention, and (6) performance bugs.For each bug in gDefects4DL, we describe why it is general and group the bugs with similar root causes and fix solutions for reference. Moreover, gDefects4DL also maintains (1) its buggy/fixed versions and the isolated fix change, (2) an isolated environment to replicate the defect, and (3) the whole code evolution history from the buggy version to the fixed version. We design gDefects4DL with extensible interfaces to evaluate software engineering methodologies and tools. We have integrated tools such as ShapeFlow, DEBAR, and GRIST. gDefects4DL contains 64 bugs falling into 6 categories (i.e., API Misuse, Shape Mismatch, Number Error, Type Mismatch, Violation of Architecture Convention, and Performance Bug). gDefects4DL is available at https://github.com/llmhyy/defects4dl, its online web demonstration is at http://47.93.14.147:9000/bugList, and the demo video is at https://youtu.be/0XtaEt4Fhm4.
ER  - 

TY  - CONF
TI  - Improving Students’ Testing Practices
T2  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
SP  - 218
EP  - 221
AU  - G. R. Bai
AU  - K. T. Stolee
PY  - 2020
DO  - 
JO  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
IS  - 
SN  - 2574-1926
VO  - 
VL  - 
JA  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
Y1  - 5-11 Oct. 2020
AB  - Software testing prevents and detects the introduction of faults and bugs during the process of evolving and delivering reliable software. As an important software development activity, testing has been intensively studied to measure test code quality and effectiveness, and assist professional developers and testers with automated test generation tools. In recent years, testing has been attracting educators' attention and has been integrated into some Computer Science education programs. Understanding challenges and problems faced by students can help inform educators the topics that require extra attention and practice when presenting testing concepts and techniques. In my research, I study how students implement and modify source code given unit tests, and how they perceive and perform unit testing. I propose to quantitatively measure the quality of student-written test code, and qualitatively identify the common mistakes and bad smells observed in student-written test code. We compare the performance of students and professionals, who vary in prior testing experience, to investigate the factors that lead to high-quality test code. The ultimate goal of my research is to address the challenges students encountered during test code composition and improve their testing skills with supportive tools or guidance.
ER  - 

TY  - CONF
TI  - Test and Evaluation Harnesses for Learning Systems
T2  - 2022 IEEE AUTOTESTCON
SP  - 1
EP  - 6
AU  - T. Cody
AU  - P. Beling
AU  - L. Freeman
PY  - 2022
DO  - 10.1109/AUTOTESTCON47462.2022.9984783
JO  - 2022 IEEE AUTOTESTCON
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 IEEE AUTOTESTCON
Y1  - 29 Aug.-1 Sept. 2022
AB  - There is an increasing demand for operational uses of machine learning (ML), however, a lack of best practices for test and evaluation (T &E) of learning systems is a hindrance to supply. This manuscript proposes a new framework for best practices, described as T &E harnesses, that corresponds principally to the task of engineering a learning system-in contrast to the status quo task of solving a learning problem. The primary difference is a question of scope. This manuscript places T &E for ML into the broader scope of systems engineering processes. Importantly, two challenge problems, acquisition and operations, are used to motivate the use of T &E harnesses for learning systems. This manuscript draws from recent findings in experimental design for ML, combinatorial interaction testing of ML solutions, and the general systems modeling of ML. The concept of T &E harnesses is closely tied to existing models of systems engineering processes. We draw the conclusion that existing best practices for T &E form a subset of what is needed to rigorously test for system-level satisfaction of stakeholder needs.
ER  - 

TY  - CONF
TI  - Code Coverage Similarity Measurement Using Machine Learning for Test Cases Minimization
T2  - 2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)
SP  - 287
EP  - 291
AU  - M. C. Saputra
AU  - T. Katayama
PY  - 2020
DO  - 10.1109/GCCE50665.2020.9291990
JO  - 2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)
IS  - 
SN  - 2378-8143
VO  - 
VL  - 
JA  - 2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)
Y1  - 13-16 Oct. 2020
AB  - Machine learning approach for minimizing the number of test cases on the test suite is an interesting research area on software testing. The research tries to minimize the number of test cases on the test suite by minimizing redundant test cases based on similarity classification. The Support Vector Machine, K-Nearest Neighbour, and Decision tree classify similar test cases by comparing the lines executed by test cases. The result has shown that the support vector machine is the highest score on accuracy and the lowest score on error rate comparing with K-Nearest Neighbour, and Decision tree. Minimize the redundant test cases increase the quality of the test cases, and reducing time on the testing process.
ER  - 

TY  - CONF
TI  - The Road Toward Dependable AI Based Systems
T2  - 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)
SP  - 2
EP  - 2
AU  - P. Tonella
PY  - 2023
DO  - 10.1109/ICSE48619.2023.00011
JO  - 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)
IS  - 
SN  - 1558-1225
VO  - 
VL  - 
JA  - 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)
Y1  - 14-20 May 2023
AB  - With the advent of deep learning, AI components have achieved unprecedented performance on complex, human competitive tasks, such as image, video, text and audio processing. Hence, they are increasingly integrated into sophisticated software systems, some of which (e.g., autonomous vehicles) are required to deliver certified dependability warranties. In this talk, I will consider the unique features of AI based systems and of the faults possibly affecting them, in order to revise the testing fundamentals and redefine the overall goal of testing, taking a statistical view on the dependability warranties that can be actually delivered. Then, I will consider the key elements of a revised testing process for AI based systems, including the test oracle and the test input generation problems. I will also introduce the notion of runtime supervision, to deal with unexpected error conditions that may occur in the field. Finally, I will identify the future steps that are essential to close the loop from testing to operation, proposing an empirical framework that reconnects the output of testing to its original goals.
ER  - 

TY  - CONF
TI  - An Effective Undersampling Approach to Deal with Class Imbalance Problem in Software Defect Prediction
T2  - 2022 19th International Bhurban Conference on Applied Sciences and Technology (IBCAST)
SP  - 225
EP  - 230
AU  - S. Fawad-ul-Hassan Gillani
AU  - A. Nadeem
AU  - M. Rizwan
PY  - 2022
DO  - 10.1109/IBCAST54850.2022.9990218
JO  - 2022 19th International Bhurban Conference on Applied Sciences and Technology (IBCAST)
IS  - 
SN  - 2151-1411
VO  - 
VL  - 
JA  - 2022 19th International Bhurban Conference on Applied Sciences and Technology (IBCAST)
Y1  - 16-20 Aug. 2022
AB  - Machine learning based software defect prediction (SDP) approaches assist in estimating where faults are likely to occur in source code. In real-life projects, fault-free modules are higher in number than faulty modules. This is referred to as class imbalance problem. Random over-sampling and random under-sampling (RUS) are the basic sampling strategies in data-level approaches for class imbalance problem. The RUS approach removes the instances randomly and due to randomness, loss of useful information may occur. On the other hand, over-sampling may lead to biased modeling. In this paper, we propose a new technique known as Structured Under-Sampling (SUS) to address both of these problems. The proposed approach systematically removes inconsistent and redundant instances. After that, most similar instances to the existing instances are removed to ensure minimum loss of information. For empirical evaluation, C4.5 classifier has been used to compare SUS with RUS and Tomek RUS while performance difference has been analyzed using F1-score and ROC. The results of our investigation show improved performance of SUS over other approaches. Moreover, it has been observed that the Imbalance ratio (IR) affects the performance of SUS. More specifically, when IR > 5 SUS outperformed in all results.
ER  - 

TY  - CONF
TI  - Manifold for Machine Learning Assurance
T2  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
SP  - 97
EP  - 100
AU  - T. Byun
AU  - S. Rayadurgam
PY  - 2020
DO  - 
JO  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
Y1  - 5-11 Oct. 2020
AB  - The increasing use of machine-learning (ML) enabled systems in critical tasks fuels the quest for novel verification and validation techniques yet grounded in accepted system assurance principles. In traditional system development, model-based techniques have been widely adopted, where the central premise is that abstract models of the required system provide a sound basis for judging its implementation. We posit an analogous approach for ML systems using an ML technique that extracts from the high-dimensional training data implicitly describing the required system, a low-dimensional underlying structure-a manifold. It is then harnessed for a range of quality assurance tasks such as test adequacy measurement, test input generation, and runtime monitoring of the target ML system. The approach is built on variational autoencoder, an unsupervised method for learning a pair of mutually near-inverse functions between a given high-dimensional dataset and a low-dimensional representation. Preliminary experiments establish that the proposed manifold-based approach, for test adequacy drives diversity in test data, for test generation yields fault-revealing yet realistic test cases, and for run-time monitoring provides an independent means to assess trustability of the target system's output.
ER  - 

TY  - CONF
TI  - Implementation of Machine Learning Techniques in Software Reliability: A framework
T2  - 2019 International Conference on Automation, Computational and Technology Management (ICACTM)
SP  - 241
EP  - 245
AU  - M. Banga
AU  - A. Bansal
AU  - A. Singh
PY  - 2019
DO  - 10.1109/ICACTM.2019.8776830
JO  - 2019 International Conference on Automation, Computational and Technology Management (ICACTM)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2019 International Conference on Automation, Computational and Technology Management (ICACTM)
Y1  - 24-26 April 2019
AB  - In this paper review of existing literature in the field of software reliability models based on machine learning techniques presented. Software reliability is very useful tool in determining the software quality. By using machine learning techniques for getting unhidden parameters affecting software fault prediction for exploring various parameters leading to obsoleteness of software by presenting category of papers of software reliability, software fault prediction, software trustworthiness, software reusability, using machine learning techniques based on statistical inferences which could predict useful pattern on hidden data of faulty software database of empirical datasets related to software testing. After studying plenary relevant papers on faults generated during fault removal, faults already present, we proposed a novel approach based on identifying most relevant parameter affecting the software reliability using Machine Learning Techniques.
ER  - 

TY  - JOUR
TI  - International Comparative Studies on the Software Testing Profession
T2  - IT Professional
SP  - 56
EP  - 61
AU  - L. F. Capretz
AU  - P. Waychal
AU  - J. Jia
AU  - D. Varona
AU  - Y. Lizama
PY  - 2021
DO  - 10.1109/MITP.2020.3031862
JO  - IT Professional
IS  - 5
SN  - 1941-045X
VO  - 23
VL  - 23
JA  - IT Professional
Y1  - 1 Sept.-Oct. 2021
AB  - This work attempts to fill a gap by exploring the human dimension in particular, by trying to understand the motivation of software professionals for taking up and sustaining their careers as software testers. Towards that goal, four surveys were conducted in four countries—India, Canada, Cuba, and China—to try to understand how professional software engineers perceive and value work-related factors that could influence their motivation to start or move into software testing careers. From our sample of 220 software professionals, we observed that very few were keen to take up testing careers. Some aspects of software testing, such as the potential for learning opportunities and the importance of the job, appear to be common motivators across the four countries, whereas the treatment of testers as second-class citizens and the complexity of the job appeared to be the most prominent de-motivators.
ER  - 

TY  - CONF
TI  - Software Testing Based on Software Product Quality Metrics (SPQM)
T2  - 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS)
SP  - 2151
EP  - 2156
AU  - V. SivaKrishna
AU  - P. S. Kumar
AU  - J. Jhaveri
AU  - L. S. Akanksha
AU  - P. V. Rao
AU  - N. R. Sai
PY  - 2023
DO  - 10.1109/ICACCS57279.2023.10113076
JO  - 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS)
IS  - 
SN  - 2575-7288
VO  - 1
VL  - 1
JA  - 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS)
Y1  - 17-18 March 2023
AB  - Producinghigh-quality products has emerged-as a crucial component of corporate success in today's marketplace. In this regard, establishing and holding to software product to assess the present quality standardto environment and promote system to improvethe quality of the productit significance. Testing software is an essential step in the software development process. This technique is more accurate and effective when it is automated. Emerged new testing tools for automated testing. The selection of the proper tools has become a challenging and confusing activity as a result of the abundance and variety of testing instruments. The current study attempts to assess the current research areas and trends on this subject that have appeared in the literature over the previous twelve years. Based on their titles and abstracts, 50 conference and article papers on SPQM published in the interval 2010 and 2022 were subjected to Systematic Mapping (SM) research. The findings are presented using a combination of diagrams, written explanations, and mind-mapping techniques, which include a trend map for the period from 2010 to 2022, details about the field and measurement techniques, identified areas for improvement, and consistency across sources such as conference papers, journal articles, and internationally recognized quality models. Future research that aims to advance this important topic may build on the outcome of this study. This research may provide a starting point for further investigations meant to advance this vital area of study
ER  - 

TY  - CONF
TI  - Fail-Safe Execution of Deep Learning based Systems through Uncertainty Monitoring
T2  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 24
EP  - 35
AU  - M. Weiss
AU  - P. Tonella
PY  - 2021
DO  - 10.1109/ICST49551.2021.00015
JO  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 12-16 April 2021
AB  - Modern software systems rely on Deep Neural Networks (DNN) when processing complex, unstructured inputs, such as images, videos, natural language texts or audio signals. Provided the intractably large size of such input spaces, the intrinsic limitations of learning algorithms and the ambiguity about the expected predictions for some of the inputs, not only there is no guarantee that DNN’s predictions are always correct, but rather developers must safely assume a low, though not negligible, error probability. A fail-safe Deep Learning based System (DLS) is one equipped to handle DNN faults by means of a supervisor, capable of recognizing predictions that should not be trusted and that should activate a healing procedure bringing the DLS to a safe state.In this paper, we propose an approach to use DNN uncertainty estimators to implement such supervisor. We first discuss advantages and disadvantages of existing approaches to measure uncertainty for DNNs and propose novel metrics for the empirical assessment of the supervisor that rely on such approaches. We then describe our publicly available tool UNCERTAINTY-WIZARD, which allows transparent estimation of uncertainty for regular tf.keras DNNs. Lastly, we discuss a large-scale study conducted on four different subjects to empirically validate the approach, reporting the lessons-learned as guidance for software engineers who intend to monitor uncertainty for fail-safe execution of DLS.
ER  - 

TY  - CONF
TI  - Invited Paper: What is AI Software Testing? and Why
T2  - 2019 IEEE International Conference on Service-Oriented System Engineering (SOSE)
SP  - 27
EP  - 2709
AU  - J. Gao
AU  - C. Tao
AU  - D. Jie
AU  - S. Lu
PY  - 2019
DO  - 10.1109/SOSE.2019.00015
JO  - 2019 IEEE International Conference on Service-Oriented System Engineering (SOSE)
IS  - 
SN  - 2642-6587
VO  - 
VL  - 
JA  - 2019 IEEE International Conference on Service-Oriented System Engineering (SOSE)
Y1  - 4-9 April 2019
AB  - With the fast advance of artificial intelligence technology and data-driven machine learning techniques, building high-quality AI-based software in different application domains is becoming a very hot research topic in both academic and industry communities. Today, many machine learning models and artificial technologies have been developed to build smart application systems based on multimedia inputs to achieve intelligent functional features, such as recommendation, object detection, classification, and prediction, natural language processing and translation, and so on. This brings strong demand in quality validation and assurance for AI software systems. Current research work seldom discusses AI software testing questions, challenges, and validation approaches with clear quality requirements and criteria. This paper focuses on AI software quality validation, including validation focuses, features, and process, and potential testing approaches. Moreover, it presents a test process and a classification-based test modeling for AI classification function testing. Finally, it discusses the challenges, issues, and needs in AI software testing.
ER  - 

TY  - CONF
TI  - Detecting Operational Adversarial Examples for Reliable Deep Learning
T2  - 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S)
SP  - 5
EP  - 6
AU  - X. Zhao
AU  - W. Huang
AU  - S. Schewe
AU  - Y. Dong
AU  - X. Huang
PY  - 2021
DO  - 10.1109/DSN-S52858.2021.00013
JO  - 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S)
Y1  - 21-24 June 2021
AB  - The utilisation of Deep Learning (DL) raises new challenges regarding its dependability in critical applications. Sound verification and validation methods are needed to assure the safe and reliable use of DL. However, state-of-the-art debug testing methods on DL that aim at detecting adversarial examples (AEs) ignore the operational profile, which statistically depicts the software’s future operational use. This may lead to very modest effectiveness on improving the software’s delivered reliability, as the testing budget is likely to be wasted on detecting AEs that are unrealistic or encountered very rarely in real-life operation. In this paper, we first present the novel notion of “operational AEs” which are AEs that have relatively high chance to be seen in future operation. Then an initial design of a new DL testing method to efficiently detect “operational AEs” is provided, as well as some insights on our prospective research plan.
ER  - 

TY  - CONF
TI  - Reports Aggregation of Crowdsourcing Test Based on Feature Fusion
T2  - 2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)
SP  - 51
EP  - 59
AU  - L. Cai
AU  - N. Wang
AU  - M. Chen
AU  - J. Wang
AU  - J. Wang
AU  - J. Gong
PY  - 2021
DO  - 10.1109/QRS-C55045.2021.00018
JO  - 2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)
IS  - 
SN  - 2693-9371
VO  - 
VL  - 
JA  - 2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)
Y1  - 6-10 Dec. 2021
AB  - In recent years, a new testing method based on the concept of crowdsourcing has made great progress. Developers upload the project to the crowdsourcing test platform and recruit a large number of crowdsourcing workers for testing, so that the testing process has higher test adequacy, faster testing speed and lower testing cost. However, the test reports submitted after the test have serious problems such as large quantity and high similarity, resulting in the failure to achieve the expected results. Based on the method of feature fusion, this paper integrates the text description information, bug type information and screenshot information of crowdsourcing test reports, clusters crowdsourcing test reports through the calculation of similarity between reports, and finally achieves better results.
ER  - 

TY  - CONF
TI  - Test Data Generation for MC/DC Criterion using Reinforcement Learning
T2  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 354
EP  - 357
AU  - J. Čegiň
AU  - K. Rástočný
PY  - 2020
DO  - 10.1109/ICSTW50294.2020.00063
JO  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 24-28 Oct. 2020
AB  - Unit testing focused on MC/DC criterion is essential in development of safety-critical systems. However design of test data that meet the MC/DC criterion needs detailed manual analysis of branching in units under test by test engineers. To deal with this problem we propose a new test data generation approach based on reinforcement learning, which utilize analogy with a game, in which a gamer, the test engineer, plays in an environment, a unit under test, and tries to achieve the highest possible reward, MC/DC coverage. We evaluated our approach for two different granularity levels, test suite and test case, and for two different action types allowed to the gamer, discrete and continuous action spaces. Preliminary results shows that the proposed approach could solve path explosion problem of symbolic approaches and that the proposed approach achieves at least comparable results to the current state-of-the-art search-based test data generation approaches.
ER  - 

TY  - CONF
TI  - Secure Modules for Undergraduate Software Engineering Courses
T2  - 2018 IEEE Frontiers in Education Conference (FIE)
SP  - 1
EP  - 5
AU  - J. Yang
AU  - A. Lodgher
AU  - Y. Lee
PY  - 2018
DO  - 10.1109/FIE.2018.8658433
JO  - 2018 IEEE Frontiers in Education Conference (FIE)
IS  - 
SN  - 2377-634X
VO  - 
VL  - 
JA  - 2018 IEEE Frontiers in Education Conference (FIE)
Y1  - 3-6 Oct. 2018
AB  - Security affects every software component in different types of computing systems. Many vulnerabilities and attacks on software systems are due to security weaknesses in the software itself. During the process of software specification, development, or testing, security issues are either taken into consideration insufficiently or not at all. Such software, due to internal weaknesses is prone to new attacks. By teaching secure software engineering techniques for designing and developing software modules, students would learn systematic secure software development techniques, such as defect detecting and security testing. This paper presents a series of modules that are designed to be integrated into undergraduate software engineering courses from a security perspective. The goal of the modules is to teach the building of robust software security requirements, secure software design and development, and secure software verification through a secure software development lifecycle.
ER  - 

TY  - CONF
TI  - Bridging Fuzz Testing and Metamorphic Testing for Classification of Machine Learning
T2  - 2022 IEEE International Conference on Consumer Electronics (ICCE)
SP  - 1
EP  - 2
AU  - D. Kang
PY  - 2022
DO  - 10.1109/ICCE53296.2022.9730476
JO  - 2022 IEEE International Conference on Consumer Electronics (ICCE)
IS  - 
SN  - 2158-4001
VO  - 
VL  - 
JA  - 2022 IEEE International Conference on Consumer Electronics (ICCE)
Y1  - 7-9 Jan. 2022
AB  - Artificial Intelligence (AI) built-in Consumer Electronics is popular, but it is hard to test and evaluate AI-based system with the existing performance metrics. Even though AI-based systems are implemented in software with flexibility, bias and non-determinism property etc., they can suffer the same defects as other software. That is why new software testing approaches are needed when testing AI-based systems. Therefore, this paper proposes a bridging approach between fuzz testing and metamorphic testing focus on the classification of machine learning. This approach can be used as a test oracle for classification of training data.
ER  - 

TY  - JOUR
TI  - Object-Oriented Test Case Generation Using Teaching Learning-Based Optimization (TLBO) Algorithm
T2  - IEEE Access
SP  - 110879
EP  - 110888
AU  - O. Al-Masri
AU  - W. A. Al-Sorori
PY  - 2022
DO  - 10.1109/ACCESS.2022.3214841
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 10
VL  - 10
JA  - IEEE Access
Y1  - 2022
AB  - Researchers are currently seeking effective methods for automated software testing to reduce time, avoid test case redundancy, and create comprehensive test cases to cover (paths, benches, conditions, and statements). Generating a minimum number of test cases and covering all code paths is challenging in automated test case generation. Therefore, the use of optimization algorithms has become a popular trend for generating test cases to achieve many goals. In this study, we used a teaching-learning-based optimization algorithm to generate the minimum number of test cases. We compared our results with those of other state-of-the-art methods based on the path coverage for ten Java programs. The motive for using this algorithm is to optimize the number of test cases that cover all code paths in the unit test. The results emphasize that the proposed algorithm generates the minimum number of test cases and covers all paths in the code at a full-coverage rate.
ER  - 

TY  - JOUR
TI  - A Study of Incorporation of Deep Learning Into Software Reliability Modeling and Assessment
T2  - IEEE Transactions on Reliability
SP  - 1621
EP  - 1640
AU  - C. -Y. Wu
AU  - C. -Y. Huang
PY  - 2021
DO  - 10.1109/TR.2021.3105531
JO  - IEEE Transactions on Reliability
IS  - 4
SN  - 1558-1721
VO  - 70
VL  - 70
JA  - IEEE Transactions on Reliability
Y1  - Dec. 2021
AB  - Software is widely used in many application domains. The most popular software are used by millions every day. How to accurately predict and assess the reliability of developed software is becoming increasingly important for project managers and developers. Previous studies have primarily used the software reliability growth model (SRGM) to evaluate and predict software reliability, but prediction results cannot be accurate at particular times or in particular situations. One of the main reasons is that simplified assumptions and abstractions are usually made to simplify the problem when developing SRGMs. Selecting an appropriate SRGM should depend on the key characteristics of the software project. In this article, we propose a deep learning-based approach for software reliability prediction and assessment. Specifically, we clearly demonstrate how to derive mathematical expressions from the computational methods of deep learning models and how to determine the correlation between them and the mathematical formula of SRGMs, and then, we use the back-propagation algorithm to obtain the SRGM parameters. Furthermore, we further integrate some deep learning-based SRGMs and also propose a method for the weighted assignment of combinations. Three real open source software failure datasets are used to evaluate the performance of the proposed models compared to selected SRGMs. The experimental results reveal that our proposed deep learning-based models and their combinations perform better than several classical SRGMs.
ER  - 

TY  - CONF
TI  - Questionnaire Approach for Assessing Software Engineering and Quality Assurance Practices
T2  - 2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)
SP  - 1301
EP  - 1306
AU  - T. Hynninen
AU  - S. Jantunen
PY  - 2022
DO  - 10.23919/MIPRO55190.2022.9803658
JO  - 2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)
IS  - 
SN  - 2623-8764
VO  - 
VL  - 
JA  - 2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)
Y1  - 23-27 May 2022
AB  - The industry-academia gap is one of the persistent challenges of Software Engineering education. Software development is a rapidly moving industry, and academia is not quick enough to adapt to the changing software engineering profession. To this end, this paper introduces a project that seeks to bridge the Software Engineering -related industry-academia gap in the Finnish region of South Savo. The project intends to bring together regional software engineering companies with teachers, developers, and students in higher education. The objective of such a community is to provide a platform for discussion and the development of collaborative models to improve education and interaction. As the first step towards building the community, we are building a better understanding of the software development companies in the region. In this paper, we describe our method of inquiry and early experiences for understanding companies’ type of business, software engineering activities, and attitude towards collaboration. The preliminary results show that our method of inquiry was perceived as useful for both industry and academia. While we were able to gather useful information about the industry practices and feedback for higher education about the skills graduates should possess, industry representatives considered the data gathering as an opportunity for self-reflection.
ER  - 

TY  - CONF
TI  - A Comprehensive Experiment Approach to Enhancing Computer Engineering Ability
T2  - 2022 IEEE Frontiers in Education Conference (FIE)
SP  - 1
EP  - 8
AU  - L. Zhang
AU  - J. Niu
PY  - 2022
DO  - 10.1109/FIE56618.2022.9962680
JO  - 2022 IEEE Frontiers in Education Conference (FIE)
IS  - 
SN  - 2377-634X
VO  - 
VL  - 
JA  - 2022 IEEE Frontiers in Education Conference (FIE)
Y1  - 8-11 Oct. 2022
AB  - This Research to Practice Full Paper presented a comprehensive experiment approach to enhancing computer engineering ability. This approach integrated Swift programming language, iOS development, UML, software testing, MVC, Cocoa Touch Framework and Design Patterns into a comprehensive experiment, through which students can master the engineering methods to solve complex application problems.In college, traditional computer programming courses focus on the grammar and classical algorithm of programming language. Usually the amount of code is far lower than that of industrial products. Such programming courses can’t effectively improve students’ ability to solve complex engineering problems. They also can’t meet the requirements of industrial development. Students are not satisfied with the results of these courses. There is an intense need for the studies of enhancing student’s computer engineering ability.Taking Swift Language Programming course as an example, this paper presented a comprehensive experiment approach to enhancing students’ computer engineering ability by developing classic industrial iOS Apps.Flipped classroom pedagogy is conducive to free much time in class. Lecturers can fully communicate with students and help students complete challenging tasks. The comprehensive experiment consists of pre-class activities and in-class activities. Before class, the lecturer provides experiment materials online including theoretical handouts of Design Patterns, manuals of UML 2.0 specifications and Cocoa Touch reference manual, etc. Students learn the materials by themselves, practice and discuss online and complete the corresponding pre-class tests. In class, the lecturer analyzes in detail the problems students encounter after class and guides them to solve these problems. The lecturer also participates in each group discussion to ensure the smooth progress of students’ project.The implementation of comprehensive experiment is divided into four sub tasks. These tasks are app function analysis, App detailed design, programming implementation, and App release and launch. First, according to the requirements of the App, the function is analyzed in detail and defined with UML. Second, based on functional analysis, the App’s system architecture, data structure, view combination, logic execution process and core algorithms are designed. The system is defined in detail with UML Class diagram. Third, according to the detailed design of the App, user interface is built by Xcode storyboard, and the model layer, view layer and control layer are implemented in Swift. Then unit test and system test are conducted on the App and bugs are repaired. Finally, App launch is completed including App internationalization, developer certificate applying, creating description file, setting product identification and deployment information, and submitting App online.To assess the effect of this comprehensive experiment approach, three-year teaching data were analyzed using statistical methods. The results show that students’ engineering ability (measured by code scale) and student satisfaction (measured by questionnaires) were significantly improved.Our contribution is to propose a detailed comprehensive experiment approach to enhancing computer engineering ability. The analysis of teaching data show that it is helpful to improve students’ computer engineering ability and course satisfaction.
ER  - 

TY  - CONF
TI  - Combinatorial Methods for Explainable AI
T2  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 167
EP  - 170
AU  - D. R. Kuhn
AU  - R. N. Kacker
AU  - Y. Lei
AU  - D. E. Simos
PY  - 2020
DO  - 10.1109/ICSTW50294.2020.00037
JO  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 24-28 Oct. 2020
AB  - This short paper introduces an approach to producing explanations or justifications of decisions made by artificial intelligence and machine learning (AI/ML) systems, using methods derived from fault location in combinatorial testing. We use a conceptually simple scheme to make it easy to justify classification decisions: identifying combinations of features that are present in members of the identified class and absent or rare in non-members. The method has been implemented in a prototype tool, and examples of its application are given.
ER  - 

TY  - CONF
TI  - SUPERNOVA: Automating Test Selection and Defect Prevention in AAA Video Games Using Risk Based Testing and Machine Learning
T2  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 345
EP  - 354
AU  - A. Senchenko
AU  - N. Patterson
AU  - H. Samuel
AU  - D. Ispir
PY  - 2022
DO  - 10.1109/ICST53961.2022.00043
JO  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 4-14 April 2022
AB  - Testing video games is an increasingly difficult task as traditional methods fail to scale with growing software systems. Manual testing is a very labor-intensive process, and therefore quickly becomes cost prohibitive. Using scripts for automated testing is affordable, however scripts are ineffective in non-deterministic environments, and knowing when to run each test is another problem altogether. Manual testing and writing scripts make up the current industry standard and methodology for game testing, but the writing is on the wall for this practice. The modern game's complexity, scope, and player expectations are rapidly increasing where quality control is a big portion of the production cost and delivery risk. Reducing this risk and making production happen is a big challenge for the industry currently. To keep production costs realistic up-to and after release, we are focusing on preventive quality assurance tactics alongside testing and data analysis automation. We present SUPERNOVA (Selection of tests and Universal defect Prevention in External Repositories for Novel Objective Verification of software Anomalies), a system responsible for test selection and defect prevention while also functioning as an automation hub. By integrating data analysis functionality with machine and deep learning capability, SUPERNOVA assists quality assurance testers in finding bugs and developers in reducing defects, which improves stability during the production cycle and keeps testing costs under control. The direct impact of this has been observed to be a reduction in 55% or more testing hours for an undisclosed sports game title that has shipped, which was using these test selection optimizations. Furthermore, using risk scores generated by a semi-supervised machine learning model, we are able to detect with 71% precision and 77% recall the probability of a change-list being bug inducing, and provide a detailed breakdown of this inference to developers. These efforts improve workflow and reduce testing hours required on game titles in development.
ER  - 

TY  - CONF
TI  - Comparing the Popularity of Testing Careers Among Canadian, Chinese, and Indian Students
T2  - 2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
SP  - 258
EP  - 259
AU  - L. F. Capretz
AU  - P. Waychal
AU  - J. Jia
PY  - 2019
DO  - 10.1109/ICSE-Companion.2019.00103
JO  - 2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
IS  - 
SN  - 2574-1934
VO  - 
VL  - 
JA  - 2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
Y1  - 25-31 May 2019
AB  - Despite its importance, software testing is, arguably, the least understood part of the software life cycle and still the toughest to perform correctly. Many researchers and practitioners have been working to address the situation. However, most of the studies focus on the process and technology dimensions and only a few on the human dimension of testing, in spite of the reported relevance of human aspects of software testing. Testers need to understand various stakeholders' explicit and implicit requirements, be aware of how developers work individually and in teams, and develop skills to report test results wisely to stakeholders.These multifaceted qualifications lend vitality to the human dimension in software testing. Exploring this human dimension carefully may help understand testing in a better way.
ER  - 

TY  - CONF
TI  - AgentFuzz: Fuzzing for Deep Reinforcement Learning Systems
T2  - 2022 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
SP  - 110
EP  - 113
AU  - T. Li
AU  - X. Wan
AU  - M. M. Özbek
PY  - 2022
DO  - 10.1109/ISSREW55968.2022.00049
JO  - 2022 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
Y1  - 31 Oct.-3 Nov. 2022
AB  - In recent years, deep reinforcement learning (DRL) technology has developed rapidly, and the application of DRL has been extended to many fields such as game gaming, au-tonomous driving, financial transactions, and robot control. As DRL applications expand and enrich, quality assurance of DRL software is increasingly important, especially in safety -critical areas. Therefore, it is necessary and urgent to adequately test DRL models to ensure the reliability and security of DRL systems. However, due to fundamental differences, traditional software testing methods cannot be directly applied to D RL systems. To bridge this gap, we introduce a new DRL system testing framework in this proposal, which aims to generate various test cases that can cause D RL systems to fail. The proposed testing framework is the first fuzzing framework for systematically testing DRL systems which we call AgentFuzz.
ER  - 

TY  - CONF
TI  - Survival of the Tested: Gamified Unit Testing Inspired by Battle Royale
T2  - 2023 IEEE/ACM 7th International Workshop on Games and Software Engineering (GAS)
SP  - 1
EP  - 7
AU  - A. Materazzo
AU  - T. Fulcini
AU  - R. Coppola
AU  - M. Torchiano
PY  - 2023
DO  - 10.1109/GAS59301.2023.00008
JO  - 2023 IEEE/ACM 7th International Workshop on Games and Software Engineering (GAS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 IEEE/ACM 7th International Workshop on Games and Software Engineering (GAS)
Y1  - 15-15 May 2023
AB  - While testing takes on a fundamental role to verify software quality and correctness, it often results to be overlooked in the educational field and students often approach it unwillingly, due to its repetitiveness.Our aim is to exploit gamification to engage students by providing them with dynamics like competition, self-expression, and personal improvement.We designed and developed Unit Brawl, a gamified application meant to manage multiple rounds, each one consisting of students developing Java programs and unit tests to be executed on each other. The players collect points by writing correct code that does not make the other players’ test cases fail, or by writing test cases capable of detecting defects in the other players’ code.The results of a preliminary evaluation to assess the functionality and performance of Unit Brawllook promising. They make us confident about its stability, so we plan an evaluation with students in order to verify the effectiveness of the applied game elements in enhancing the students’ interest towards testing topics and their learning.
ER  - 

TY  - CONF
TI  - Reasoning-Based Software Testing
T2  - 2023 IEEE/ACM 45th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
SP  - 66
EP  - 71
AU  - L. Giamattei
AU  - R. Pietrantuono
AU  - S. Russo
PY  - 2023
DO  - 10.1109/ICSE-NIER58687.2023.00018
JO  - 2023 IEEE/ACM 45th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
IS  - 
SN  - 2832-7632
VO  - 
VL  - 
JA  - 2023 IEEE/ACM 45th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
Y1  - 14-20 May 2023
AB  - With software systems becoming increasingly pervasive and autonomous, our ability to test for their quality is severely challenged. Many systems are called to operate in uncertain and highly-changing environment, not rarely required to make intelligent decisions by themselves. This easily results in an intractable state space to explore at testing time. The state-of-the-art techniques try to keep the pace, e.g., by augmenting the tester’s intuition with some form of (explicit or implicit) learning from observations to search this space efficiently. For instance, they exploit historical data to drive the search (e.g., ML-driven testing) or the tests execution data itself (e.g., adaptive or search-based testing). Despite the indubitable advances, the need for smartening the search in such a huge space keeps to be pressing.We introduce Reasoning-Based Software Testing (RBST), a new way of thinking at the testing problem as a causal reasoning task. Compared to mere intuition-based or state-of-the-art learning-based strategies, we claim that causal reasoning more naturally emulates the process that a human would do to "smartly" search the space. RBST aims to mimic and amplify, with the power of computation, this ability. The conceptual leap can pave the ground to a new trend of techniques, which can be variously instantiated from the proposed framework, by exploiting the numerous tools for causal discovery and inference. Preliminary results reported in this paper are promising.
ER  - 

TY  - CONF
TI  - Deeper at the SBST 2021 Tool Competition: ADAS Testing Using Multi-Objective Search
T2  - 2021 IEEE/ACM 14th International Workshop on Search-Based Software Testing (SBST)
SP  - 40
EP  - 41
AU  - M. H. Moghadam
AU  - M. Borg
AU  - S. J. Mousavirad
PY  - 2021
DO  - 10.1109/SBST52555.2021.00018
JO  - 2021 IEEE/ACM 14th International Workshop on Search-Based Software Testing (SBST)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 IEEE/ACM 14th International Workshop on Search-Based Software Testing (SBST)
Y1  - 31-31 May 2021
AB  - Deeper is a simulation-based test generator that uses an evolutionary process, i.e., an archive-based NSGA-II augmented with a quality population seed, for generating test cases to test a deep neural network-based lane-keeping system. This paper presents Deeper briefly and summarizes the results of Deeper's participation in the Cyber-physical systems (CPS) testing competition at SBST 2021.
ER  - 

TY  - CONF
TI  - Research on Multi-objective Test Case Generation Based on Cuckoo Search
T2  - 2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)
SP  - 1619
EP  - 1623
AU  - H. Haixian
AU  - F. Jing
PY  - 2018
DO  - 10.1109/IAEAC.2018.8577228
JO  - 2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)
IS  - 
SN  - 2381-0947
VO  - 
VL  - 
JA  - 2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)
Y1  - 12-14 Oct. 2018
AB  - Automatic test data generation is a key link in the process of test automatic technology. In order to measure the efficiency and effectiveness of test cases from multiple perspectives, a multi-objective test case generation method based on cuckoo search is proposed. This method considers two aspects of error discovery ability and test cost, and selects branch distance and test case size as multiple optimization goals. In order to solve the problem of insufficient local search capability of basic multi-objective cuckoo search, Teaching-learning mechanism was introduced. Part of the better solutions in the evolution process were searched locally through Teaching-Learning-Based optimization. At the same time, the external archives were combined with the idea of crowd distance. Set to speed up the convergence of the algorithm. Experiments result shows that compared with the methods based on NSGA-II algorithm and MOCS algorithm, the proposed method can obtain better Pareto solution set and get higher quality test cases in a shorter time.
ER  - 

TY  - CONF
TI  - Searching for the Best Test
T2  - 2017 IEEE/ACM 10th International Workshop on Search-Based Software Testing (SBST)
SP  - 3
EP  - 4
AU  - T. E. J. Vos
AU  - P. Aho
PY  - 2017
DO  - 10.1109/SBST.2017.11
JO  - 2017 IEEE/ACM 10th International Workshop on Search-Based Software Testing (SBST)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2017 IEEE/ACM 10th International Workshop on Search-Based Software Testing (SBST)
Y1  - 22-23 May 2017
AB  - Random testing has been controversial throughout the history. In the early 70s opinions about random testing were divided: Girard and Rault (1973) call it a valuable test case generation scheme [11]. This is confirmed by Thayer, Lipow and Nelson (1978) in their book on software reliability [21] they say it is the necessary final step in the testing activities. However, Glenford Myers (1979) in his seminal work on the art of Software Testing [18] denominates random testing as probably the poorest testing method.
ER  - 

TY  - CONF
TI  - Identifying Software Test Architect Skills and Knowledge
T2  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 213
EP  - 215
AU  - D. Jon
AU  - L. Hagar
PY  - 2020
DO  - 10.1109/ICSTW50294.2020.00044
JO  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 24-28 Oct. 2020
AB  - The software industry has grown from simple programmers doing almost every job when creating software programs, to one where there are many titled engineering specialists listed in job postings. For a number of years, the use of the term “architect” has appeared in system, software and test job postings. This paper explores the important knowledge and skills of a software test architect and why they are needed.
ER  - 

TY  - CONF
TI  - Mind the Gap: Are Practitioners and Researchers in Software Testing Speaking the Same Language?
T2  - 2019 IEEE/ACM Joint 7th International Workshop on Conducting Empirical Studies in Industry (CESI) and 6th International Workshop on Software Engineering Research and Industrial Practice (SER&IP)
SP  - 10
EP  - 17
AU  - R. E. S. Santos
AU  - A. Bener
AU  - M. T. Baldassarre
AU  - C. V.C. Magalhães
AU  - J. S. Correia-Neto
AU  - F. Q. B. da Silva
PY  - 2019
DO  - 10.1109/CESSER-IP.2019.00010
JO  - 2019 IEEE/ACM Joint 7th International Workshop on Conducting Empirical Studies in Industry (CESI) and 6th International Workshop on Software Engineering Research and Industrial Practice (SER&IP)
IS  - 
SN  - 2575-4793
VO  - 
VL  - 
JA  - 2019 IEEE/ACM Joint 7th International Workshop on Conducting Empirical Studies in Industry (CESI) and 6th International Workshop on Software Engineering Research and Industrial Practice (SER&IP)
Y1  - 28-28 May 2019
AB  - Context. Software testing is the area of software engineering focused on determining whether a software meets the planned requirements and on evaluating its quality. Lately, academic researchers have increased their attention in this topic due to the impact of its success on software projects. However, recent studies have discussed that practitioners and researchers might have different views regarding what is important to explore and study in order to improve the software testing process. Goal. This study aims to investigate the differences of interests between academic researchers and practitioners in software testing, pointing out observable convergences and divergences between the two communities. Method. A mixed-method approach based on a mapping study, a quantitative study and a focus group was applied to collect quantitative and qualitative data from professionals and academic sources. Results. Our results confirm the existence of a gap between the two communities and the findings suggest that, while researchers are mainly focused on the proposition of novel tools and techniques, practitioners are more interested in issues related to the evaluation and discussions of existing approaches, tools and techniques. Therefore, academic researchers might consider identify, understand and modify the existing tools and strategies, instead of building new ones. Conclusion. In general, the distinction between the two groups is noticeable and there is only one strong mutual interest between both practitioners and researchers, namely, test automation. Therefore, there is a need for the development of strategies that reduce the gap between academia and industrial practice and bring them closer in order to increase the quality of the software testing processes.
ER  - 

TY  - CONF
TI  - Practitioners’ Testimonials about Software Testing
T2  - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)
SP  - 582
EP  - 589
AU  - P. Waychal
AU  - L. F. Capretz
AU  - J. Jia
AU  - D. Varona
AU  - Y. Lizama
PY  - 2021
DO  - 10.1109/SANER50967.2021.00070
JO  - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)
IS  - 
SN  - 1534-5351
VO  - 
VL  - 
JA  - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)
Y1  - 9-12 March 2021
AB  - As software systems are becoming more pervasive, they are also becoming more susceptible to failures, resulting in potentially lethal combinations. Software testing is critical to preventing software failures but is, arguably, the least understood part of the software life cycle and the toughest to perform correctly. Adequate research has been carried out in both the process and technology dimensions of testing, but not in the human dimensions. This paper attempts to fill in the gap by exploring the human dimension, i.e., trying to understand the motivation of software professionals to take up and sustain testing careers. Towards that end, a survey was conducted in four countries - India, Canada, Cuba, and China - to try to understand how professional software testers perceive and value work-related factors that could influence their motivation to take up and sustain testing careers. With a sample of 220 software professionals, we observed that very few professionals are keen to take up testing careers. Some aspects of software testing, such as the learning opportunities, appear to be a common motivator across the four countries; whereas the treatment meted out to testers as second-class citizens and the complexity of the job appeared to be the most important de-motivators. This comparative study offers useful insights that can help global software industry leaders to come up with an action plan to put the software testing profession under a new light. That could increase the number of software engineers choosing testing careers, which would facilitate quality testing.
ER  - 

TY  - CONF
TI  - Fault localization in software testing using soft computing approaches
T2  - 2017 4th International Conference on Signal Processing, Computing and Control (ISPCC)
SP  - 627
EP  - 631
AU  - P. K. Singh
AU  - S. Garg
AU  - M. Kaur
AU  - M. S. Bajwa
AU  - Y. Kumar
PY  - 2017
DO  - 10.1109/ISPCC.2017.8269753
JO  - 2017 4th International Conference on Signal Processing, Computing and Control (ISPCC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2017 4th International Conference on Signal Processing, Computing and Control (ISPCC)
Y1  - 21-23 Sept. 2017
AB  - Testing is the most important and critical task in software development life cycle. Whenever software testing execution fails its test scripts is analyzed so that the point where fault occurred can be detected and the expected result can be achieved. Detecting fault in software is called as fault localization. Manually fault localization can be a cumbersome job so providing automated technique to do the same without human intervention is the demand from long time. In this paper, a brief overview of some important fault localization technique using soft computing techniques is carried out. Based on the identified points, it is identified that better result may be generated using machine learning technique along with time reduction. Prime objective of this paper is to made and attempt for identifying the fault localization techniques in combination with soft computing approaches to minimize the time and space complexities, so that the better results may be achieved in context of usability and effectiveness.
ER  - 

TY  - CONF
TI  - Sensitive Region-Based Metamorphic Testing Framework using Explainable AI
T2  - 2023 IEEE/ACM 8th International Workshop on Metamorphic Testing (MET)
SP  - 25
EP  - 30
AU  - Y. Torikoshi
AU  - Y. Nishi
AU  - J. Takahashi
PY  - 2023
DO  - 10.1109/MET59151.2023.00011
JO  - 2023 IEEE/ACM 8th International Workshop on Metamorphic Testing (MET)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 IEEE/ACM 8th International Workshop on Metamorphic Testing (MET)
Y1  - 14-14 May 2023
AB  - Deep Learning (DL) is one of the most popular research topics in machine learning and DL-driven image recognition systems have developed rapidly. Recent research has employed metamorphic testing (MT) to detect misclassified images. Most of them discuss metamorphic relations (MR), with limited attention given to which regions should be transformed. We focus on the fact that there are sensitive regions where even small transformations can easily change the prediction results and propose an MT framework that efficiently tests for regions prone to misclassification by transforming these sensitive regions. Our evaluation demonstrated that the sensitive regions can be specified by Explainable AI (XAI) and our framework effectively detects faults.
ER  - 

TY  - CONF
TI  - A Combinatorial Approach to Explaining Image Classifiers
T2  - 2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 35
EP  - 43
AU  - J. Chandrasekaran
AU  - Y. Lei
AU  - R. Kacker
AU  - D. Richard Kuhn
PY  - 2021
DO  - 10.1109/ICSTW52544.2021.00019
JO  - 2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 12-16 April 2021
AB  - Machine Learning (ML) models, a core component to artificial intelligence systems, often come as a black box to the user, leading to the problem of interpretability. Explainable Artificial Intelligence (XAI) is key to providing confidence and trustworthiness for machine learning-based software systems. We observe a fundamental connection between XAI and software fault localization. In this paper, we present an approach that uses BEN, a combinatorial testing-based software fault localization approach, to produce explanations for decisions made by ML models.
ER  - 

TY  - CONF
TI  - RiverFuzzRL - an open-source tool to experiment with reinforcement learning for fuzzing
T2  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 430
EP  - 435
AU  - C. Paduraru
AU  - M. Paduraru
AU  - A. Stefanescu
PY  - 2021
DO  - 10.1109/ICST49551.2021.00055
JO  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 12-16 April 2021
AB  - Combining fuzzing techniques and reinforcement learning could be an important direction in software testing. However, there is a gap in support for experimentation in this field, as there are no open-source tools to let academia and industry to perform experiments easily. The purpose of this paper is to fill this gap by introducing a new framework, named RiverFuzzRL, on top of our already mature frame-work for AI-guided fuzzing, River. We provide out-of-the-box implementations for users to choose from or customize for their test target. The work presented here is performed on testing binaries and does not require access to the source code, but it can be easily adapted to other types of software testing as well. We also discuss the challenges faced, opportunities, and factors that are important for performance, as seen in the evaluation.
ER  - 

TY  - CONF
TI  - A Combinatorial Approach to Fairness Testing of Machine Learning Models
T2  - 2022 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 94
EP  - 101
AU  - A. R. Patel
AU  - J. Chandrasekaran
AU  - Y. Lei
AU  - R. N. Kacker
AU  - D. R. Kuhn
PY  - 2022
DO  - 10.1109/ICSTW55395.2022.00030
JO  - 2022 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2022 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 4-13 April 2022
AB  - Machine Learning (ML) models could exhibit biased behavior, or algorithmic discrimination, resulting in unfair or discriminatory outcomes. The bias in the ML model could emanate from various factors such as the training dataset, the choice of the ML algorithm, or the hyperparameters used to train the ML model. In addition to evaluating the model’s correctness, it is essential to test ML models for fair and unbiased behavior. In this paper, we present a combinatorial testing-based approach to perform fairness testing of ML models. Our approach is model agnostic and evaluates fairness violations of a pre-trained ML model in a two-step process. In the first step, we create an input parameter model from the training data set and then use the model to generate a t-way test set. In the second step, for each test, we modify the value of one or more protected attributes to see if we could find fairness violations. We performed an experimental evaluation of the proposed approach using ML models trained with tabular datasets. The results suggest that the proposed approach can successfully identify fairness violations in pre-trained ML models.
ER  - 

TY  - JOUR
TI  - Nature-Based Prediction Model of Bug Reports Based on Ensemble Machine Learning Model
T2  - IEEE Access
SP  - 63916
EP  - 63931
AU  - S. A. Alsaedi
AU  - A. Y. Noaman
AU  - A. A. A. Gad-Elrab
AU  - F. E. Eassa
PY  - 2023
DO  - 10.1109/ACCESS.2023.3288156
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 11
VL  - 11
JA  - IEEE Access
Y1  - 2023
AB  - In software development systems, the maintenance process of software systems attracted the attention of researchers due to its importance in fixing the defects discovered in the software testing by using bug reports (BRs) which include detailed information like description, status, reporter, assignee, priority, and severity of the bug and other information. The main problem in this process is how to analyze these BRs to discover all defects in the system, which is a tedious and time-consuming task if done manually because the number of BRs increases dramatically. Thus, the automated solution is the best. Most of the current research focuses on automating this process from different aspects, such as detecting the severity or priority of the bug. However, they did not consider the nature of the bug, which is a multi-class classification problem. This paper solves this problem by proposing a new prediction model to analyze BRs and predict the nature of the bug. The proposed model constructs an ensemble machine learning algorithm using natural language processing (NLP) and machine learning techniques. We simulate the proposed model by using a publicly available dataset for two online software bug repositories (Mozilla and Eclipse), which includes six classes: Program Anomaly, GUI, Network or Security, Configuration, Performance, and Test-Code. The simulation results show that the proposed model can achieve better accuracy than most existing models, namely, 90.42% without text augmentation and 96.72% with text augmentation.
ER  - 

TY  - CONF
TI  - Exploring students' sensemaking of test case design. An initial study
T2  - 2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)
SP  - 1069
EP  - 1078
AU  - N. Doorn
AU  - T. E. J. Vos
AU  - B. Marín
AU  - H. Passier
AU  - L. Bijlsma
AU  - S. Cacace
PY  - 2021
DO  - 10.1109/QRS-C55045.2021.00161
JO  - 2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)
IS  - 
SN  - 2693-9371
VO  - 
VL  - 
JA  - 2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)
Y1  - 6-10 Dec. 2021
AB  - Testing is the most used process to assure software systems quality. With increasing complexity of software, testing is getting more important. Testing is an intellectual activity that needs to allocate multiple cognitive resources in students, making it a challenging topic to teach in computer science programs. We advocate that testing is both model-based and exploratory, meaning that we can only make useful test models for test case design once we have made enough sense about the testing problem. The latter can only be achieved through exploring, i.e. questioning, studying, observing and inferring. In this paper, we present an initial diagnostic study to understand the sensemaking used by students while creating test models. We found indications of four different approaches used by students when modelling test cases. A plan for further research is presented on how to improve teaching by taking into account the student's sensemaking approaches.
ER  - 

TY  - CONF
TI  - TCP-Net: Test Case Prioritization using End-to-End Deep Neural Networks
T2  - 2022 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 122
EP  - 129
AU  - M. Abdelkarim
AU  - R. ElAdawi
PY  - 2022
DO  - 10.1109/ICSTW55395.2022.00034
JO  - 2022 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2022 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 4-13 April 2022
AB  - Regression testing is facing a bottleneck due to the growing number of test cases and the wide adoption of continuous integration (CI) in software projects, which increases the frequency of running software builds, making it challenging to run all the regression test cases. Machine learning (ML) techniques can be used to save time and hardware resources without compromising quality. In this work, we introduce a novel end-to-end, self-configurable, and incremental learning deep neural network (DNN) tool for test case prioritization (TCP-Net). TCP-Net is fed with source code-related features, test case metadata, test case coverage information, and test case failure history, to learn a high dimensional correlation between source files and test cases. We experimentally show that TCP-Net can be efficiently used for test case prioritization by evaluating it on three different real-life industrial software packages.
ER  - 

TY  - CONF
TI  - Towards Improved Testing For Deep Learning
T2  - 2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
SP  - 85
EP  - 88
AU  - J. Sekhon
AU  - C. Fleming
PY  - 2019
DO  - 10.1109/ICSE-NIER.2019.00030
JO  - 2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)
Y1  - 25-31 May 2019
AB  - The growing use of deep neural networks in safety-critical applications makes it necessary to carry out adequate testing to detect and correct any incorrect behavior for corner case inputs before they can be actually used. Deep neural networks lack an explicit control-flow structure, making it impossible to apply to them traditional software testing criteria such as code coverage. In this paper, we examine existing testing methods for deep neural networks, the opportunities for improvement and the need for a fast, scalable, generalizable end-to-end testing method. We also propose a coverage criterion for deep neural networks that tries to capture all possible parts of the deep neural network's logic.
ER  - 

TY  - CONF
TI  - Designing Early Testing Course Curricula with Activities Matching the V-Model Phases
T2  - 2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)
SP  - 1593
EP  - 1598
AU  - T. Hynninen
AU  - A. Knutas
AU  - J. Kasurinen
PY  - 2019
DO  - 10.23919/MIPRO.2019.8757033
JO  - 2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)
IS  - 
SN  - 2623-8764
VO  - 
VL  - 
JA  - 2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)
Y1  - 20-24 May 2019
AB  - This work addresses the gap between software engineering process terminology in formal education, and the practical skills relevant to testing related work. The V-model is a commonly referenced description of how the software engineering processes are tied to the different software testing levels. It is used in software engineering education to illustrate which type of testing work should be carried out during a certain development stage. However, the V-model is mainly conceptual and tied to the steps in the Waterfall model, leaving the students with little knowledge about what is actually done. To solve this problem, we propose an approach to map the V-Model development phases and testing levels with corresponding, actual testing techniques. We then evaluate the approach by designing the weekly topics, learning goals and testing activities for a 7 week introductory course on the basics software testing and quality assurance. Based on the course outcomes and recent literature, we discuss the strengths and weaknesses of the proposed curriculum.
ER  - 

TY  - CONF
TI  - Hyperheuristic Search for SBST
T2  - 2015 IEEE/ACM 8th International Workshop on Search-Based Software Testing
SP  - 15
EP  - 16
AU  - Y. Jia
PY  - 2015
DO  - 10.1109/SBST.2015.10
JO  - 2015 IEEE/ACM 8th International Workshop on Search-Based Software Testing
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2015 IEEE/ACM 8th International Workshop on Search-Based Software Testing
Y1  - 18-19 May 2015
AB  - This paper argues that incorporating hyper heuristic techniques into existing SBST approaches could help to increase their applicability and generality. We propose a general two layer selective hyper heuristic approach for SBST and provide an example of its use for Combinatorial Interaction Testing (CIT).
ER  - 

TY  - CONF
TI  - A Preliminary Investigation into Using Machine Learning Algorithms to Identify Minimal and Equivalent Mutants
T2  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 304
EP  - 313
AU  - C. Brito
AU  - V. H. S. Durelli
AU  - R. S. Durelli
AU  - S. R. S. d. Souza
AU  - A. M. R. Vincenzi
AU  - M. E. Delamaro
PY  - 2020
DO  - 10.1109/ICSTW50294.2020.00056
JO  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 24-28 Oct. 2020
AB  - Two issues that have been hampering the widespread adoption of mutation testing are redundant and equivalent mutants. Minimal mutation has been recently introduced to mitigate these two issues by generating and selecting only a subset of non-redundant mutants. Equivalent mutants are syntactically different from the original program, but functionally identical, so it is impossible to come up with test data capable of making equivalent mutants behave differently from the original program under test. In order to mitigate the cost of applying mutation testing, we set out to investigate how machine learning algorithms that generate predictive models can be used to classify mutants as belonging to the minimal set or equivalent. More specifically, we extract a set of features (i.e., properties) from programs, mutants, and test cases, which in turn serve as input to the creation of predictive models. To shed some light on the effectiveness of our approach, we carried out an experiment in which we trained seven different machine learning classifiers, the best of which obtained 81.88% and 80.30% accuracy to classify minimal and equivalent mutants, respectively. Results from our experiment would seem to indicate that our approach can effectively mitigate some of the costs associated with mutation testing by relying on the identification of minimal sets and equivalent mutants.
ER  - 

TY  - JOUR
TI  - Machine Learning Testing: Survey, Landscapes and Horizons
T2  - IEEE Transactions on Software Engineering
SP  - 1
EP  - 36
AU  - J. M. Zhang
AU  - M. Harman
AU  - L. Ma
AU  - Y. Liu
PY  - 2022
DO  - 10.1109/TSE.2019.2962027
JO  - IEEE Transactions on Software Engineering
IS  - 1
SN  - 1939-3520
VO  - 48
VL  - 48
JA  - IEEE Transactions on Software Engineering
Y1  - 1 Jan. 2022
AB  - This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.
ER  - 

TY  - CONF
TI  - SoCa: Software Catalog
T2  - 2018 International Conference on Applied Engineering (ICAE)
SP  - 1
EP  - 6
AU  - M. K. Mufida
AU  - W. Anurogo
AU  - M. Santiputri
AU  - M. Ansori
AU  - M. Z. Lubis
PY  - 2018
DO  - 10.1109/INCAE.2018.8579367
JO  - 2018 International Conference on Applied Engineering (ICAE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 International Conference on Applied Engineering (ICAE)
Y1  - 3-4 Oct. 2018
AB  - Teaching, learning process and the research at Department of Informatics of the State Polytechnic of Batam produce many software as project based learning teaching method starts to be implemented since 2017. All softwares have been documented as files on a server and in a CD or DVD. These software of a big volume requires good management and documentation in order to get more benefit instead of stack them as archive. This research aims to record further application development such as customization and commercialization of applications as well as versioning for advanced research on certain software products. This study target to handle documentation and publication problem generated from the teaching and research activity at Department of Informatics of the State Polytechnic of Batam in the form of catalogs that accessible online. SoCa is an application developed on web platform to facilitate data access over the internet anywhere and anytime. We used waterfall software development method that starts with data collection through interviews, and observation to complete system specification, design, develop, test and then validate the testing results performed using Black Box technique. The SoCa is equipped with detailed information on applications such as application descriptions, documentation and application's version. It also provides video demonstration of software workflow and its manual book. SoCa is expected to be a solution to realize various software management problem at Department of Informatics Engineering State Polytechnic of Batam.
ER  - 

TY  - CONF
TI  - A Global View on the Hard Skills and Testing Tools in Software Testing
T2  - 2019 ACM/IEEE 14th International Conference on Global Software Engineering (ICGSE)
SP  - 143
EP  - 151
AU  - R. Florea
AU  - V. Stray
PY  - 2019
DO  - 10.1109/ICGSE.2019.00035
JO  - 2019 ACM/IEEE 14th International Conference on Global Software Engineering (ICGSE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2019 ACM/IEEE 14th International Conference on Global Software Engineering (ICGSE)
Y1  - 25-26 May 2019
AB  - Developing software with high quality is challenging in distributed software development. The purpose of the current study is to investigate the testing skills and tools required in the ever-changing world of global software engineering, according to industrial needs. We analysed 500 job ads from 33 countries. The results show that a quarter of the testers and a fifth of developers are asked to work in distributed projects. The testers are asked to be highly skilled in a variety of test activities and tools, while the testing-skills demand for developers is low and somewhat vague. The profile of testers has a strong technical component in addition to the managerial one. Our findings show that employers need most that testers are competent in automated testing. Furthermore, the industry does not cover all aspects of testing with the demand for testers and developers. Surprisingly, neither role is asked to test the implementation of the general data protection requirements. Our study bridges the industrial needs and the practitioners' skill development process. Therefore, software testers can use our study as a reference point to enhance their skills. Employers should use our results to check their testing-skill coverage within the development teams. Tertiary education providers are encouraged to use our findings, to update the curriculum in the software development area.
ER  - 

TY  - CONF
TI  - Predicting Survived and Killed Mutants
T2  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 274
EP  - 283
AU  - A. Duque-Torres
AU  - N. Doliashvili
AU  - D. Pfahl
AU  - R. Ramler
PY  - 2020
DO  - 10.1109/ICSTW50294.2020.00053
JO  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 24-28 Oct. 2020
AB  - Mutation Testing (MT) is a state-of-the-art technique for assessing test suite effectiveness. The MT principle is to inject variants, known as mutants, into the System Under Test (SUT). Then, the behaviour of the original SUT is compared to that of the mutated SUT when running the same test suite. If no difference in behaviour is observed, the mutant is said to have survived; otherwise, it is said to have been killed. Despite its strengths, the applicability of MT in practice has been limited by its high computational cost. To mitigate this problem, Predictive Mutation Testing (PMT) has been proposed. PMT uses a classification model based on features related to the mutated code and the test suite to predict the execution results of a mutant without actually executing it. In other words, PMT predicts whether a mutant will be killed or will survive. In previous studies, PMT has been evaluated on several projects in two application scenarios, involving cross-project and crossversion learning. The goal of our research is to investigate how well the proposed PMT method, which has been evaluated on Java, can be extended to other programming languages. For that purpose, we first replicated the previous study and then extended the PMT approach to a single C program. We used random forrest classifiers as our supervised learning approach of choice. Our results indicate that PMT is able to predict the execution results of mutants with high accuracy. On the Java projects, we achieved Area Under Curve (AUC) values above 0.90 with a Prediction Error (PE) below 10%. On the C project, we achieved an AUC value above 0.90 with a PE below 1%. In our analyses we also investigated how sensitive the performance of PMT is to the set of selected features. In particular, we wanted to understand whether adding programming language specific features to a language independent core set of features significantly improve the performance of PMT. Our results are an indicator that, overall, PMT has potential to be applied across programming languages and is robust when dealing with imbalanced data.
ER  - 

TY  - CONF
TI  - Uncertainty-Wizard: Fast and User-Friendly Neural Network Uncertainty Quantification
T2  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 436
EP  - 441
AU  - M. Weiss
AU  - P. Tonella
PY  - 2021
DO  - 10.1109/ICST49551.2021.00056
JO  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 12-16 April 2021
AB  - Uncertainty and confidence have been shown to be useful metrics in a wide variety of techniques proposed for deep learning testing, including test data selection and system supervision. We present Uncertainty-Wizard, a tool that allows to quantify such uncertainty and confidence in artificial neural networks. It is built on top of the industry-leading TF.KERAS deep learning API and it provides a near-transparent and easy to understand interface. At the same time, it includes major performance optimizations that we benchmarked on two different machines and different configurations.
ER  - 

TY  - JOUR
TI  - A Novel Approach to Improve Software Defect Prediction Accuracy Using Machine Learning
T2  - IEEE Access
SP  - 63579
EP  - 63597
AU  - I. Mehmood
AU  - S. Shahid
AU  - H. Hussain
AU  - I. Khan
AU  - S. Ahmad
AU  - S. Rahman
AU  - N. Ullah
AU  - S. Huda
PY  - 2023
DO  - 10.1109/ACCESS.2023.3287326
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 11
VL  - 11
JA  - IEEE Access
Y1  - 2023
AB  - In software engineering community, defect prediction is one the active domain. For the software’s success, it is essential to reduce the software engineering and data-mining gap. Software defects prediction forecasts the source code errors before the testing phase. Methods for predicting software defects, such as clustering, statistical methods, mixed algorithms, metrics based on neural networks, black box testing, white box testing and machine learning are frequently used to explore the effect area in software. The main contribution of this research is the use of feature selection for the first time to increase the accuracy of machine learning classifiers in defects pre-diction. The objective of this study is to improve the defects prediction accuracy in five data sets of NASA namely; CM1, JM1, KC2, KC1, and PC1. These NASA data sets are open to public. In this research, the feature selection technique is use with machine-learning techniques; Random Forest, Logistic Regression, Multilayer Perceptron, Bayesian Net, Rule ZeroR, J48, Lazy IBK, Support Vector Machine, Neural Networks, and Decision Stump to achieve high defect prediction accuracy as compared to without feature selection (WOFS). The research workbench, a machine-learning tool called WEKA (Waikato Environment for Knowledge Analysis), is used to refine da-ta, preprocess data, and apply the mentioned classifiers. To assess statistical analyses, a mini tab statistical tool is used. The results of this study reveals that accuracy of defects prediction with feature selection (WFS) is improve in contrast with the accuracy of WOFS.
ER  - 

TY  - JOUR
TI  - Control of Black-Box Embedded Systems by Integrating Automaton Learning and Supervisory Control Theory of Discrete-Event Systems
T2  - IEEE Transactions on Automation Science and Engineering
SP  - 361
EP  - 374
AU  - H. Zhang
AU  - L. Feng
AU  - Z. Li
PY  - 2020
DO  - 10.1109/TASE.2019.2929563
JO  - IEEE Transactions on Automation Science and Engineering
IS  - 1
SN  - 1558-3783
VO  - 17
VL  - 17
JA  - IEEE Transactions on Automation Science and Engineering
Y1  - Jan. 2020
AB  - The paper presents an approach to the control of black-box embedded systems by integrating automaton learning and supervisory control theory (SCT) of discrete-event systems (DES), where automaton models of both the system and requirements are unavailable or hard to obtain. First, the system is tested against the requirements. If all the requirements are satisfied, no supervisor is needed and the process terminates. Otherwise, a supervisor is synthesized to enforce the system to satisfy the requirements. To apply SCT and automaton learning technologies efficiently, the system is abstracted to be a finite-discrete model. Then, a C* learning algorithm is proposed based on the classical L* algorithm to infer a Moore automaton describing both the behavior of the system and the conjunctive behavior of the system and the requirements. Subsequently, a supervisor for the system is derived from the learned Moore automaton and patched on the system. Finally, the controlled system is tested again to check the correctness of the supervisor. If the requirements are still not satisfied, a larger Moore automaton is learned and a refined supervisor is synthesized. The whole process iterates until the requirements hold in the controlled system. The effectiveness of the proposed approach is manifested through two realistic case studies.
ER  - 

TY  - CONF
TI  - An automatic testing framework for embedded software
T2  - 2017 12th International Conference on Computer Science and Education (ICCSE)
SP  - 269
EP  - 274
AU  - Y. Shuaishuai
AU  - Y. Zhengwei
AU  - L. Bin
AU  - L. Yunfeng
AU  - G. Zhijie
PY  - 2017
DO  - 10.1109/ICCSE.2017.8085501
JO  - 2017 12th International Conference on Computer Science and Education (ICCSE)
IS  - 
SN  - 2473-9464
VO  - 
VL  - 
JA  - 2017 12th International Conference on Computer Science and Education (ICCSE)
Y1  - 22-25 Aug. 2017
AB  - With the widespread use of embedded software, the embedded software testing has become an indispensable part of the development process. The current representative tools for testing embedded software include ADS2 made by TechSAT, RT-LAB developed by OpalRT, and GESTE developed by Beihang University. However, their degree of automation is inadequate. Therefore, this paper studies an automatic testing framework for embedded software. It through Interface Protocol Modeling Module, Test Profile Modeling Module, Test Data Generation Module and T est Script Generation Module, to achieve platform-related test script generation. The framework greatly reduces the time for testers to design test cases.
ER  - 

TY  - CONF
TI  - PySE: Automatic Worst-Case Test Generation by Reinforcement Learning
T2  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
SP  - 136
EP  - 147
AU  - J. Koo
AU  - C. Saumya
AU  - M. Kulkarni
AU  - S. Bagchi
PY  - 2019
DO  - 10.1109/ICST.2019.00023
JO  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
Y1  - 22-27 April 2019
AB  - Stress testing is an important task in software testing, which examines the behavior of a program under a heavy load. Symbolic execution is a useful tool to find out the worst-case input values for the stress testing. However, symbolic execution does not scale to a large program, since the number of paths to search grows exponentially with an input size. So far, such a scalability issue has been mostly managed by pruning out unpromising paths in the middle of searching based on heuristics, but this kind of work easily eliminates the true worst case as well, providing sub-optimal one only. Another way to achieve scalability is to learn a branching policy of worst-case complexity from small scale tests and apply it to a large scale. However, use cases of such a method are restricted to programs whose worst-case branching policy has a simple pattern. To address such limitations, we propose PySE that uses symbolic execution to collect the behaviors of a given branching policy, and updates the policy using a reinforcement learning approach through multiple executions. PySE's branching policy keeps evolving in a way that the length of an execution path increases in the long term, and ultimately reaches the worst-case complexity. PySE can also learn the worst-case branching policy of a complex or irregular pattern, using an artificial neural network in a fully automatic way. Experiment results demonstrate that PySE can effectively find a path of worst-case complexity for various Python benchmark programs and scales.
ER  - 

TY  - CONF
TI  - Automated Test Suite for Regression Testing Based on Serenity Framework: A Case Study
T2  - 2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT)
SP  - 138
EP  - 144
AU  - F. A. K. P. G. Sutapa
AU  - S. Kusumawardani
AU  - A. E. Permanasari
PY  - 2019
DO  - 10.1109/ICAIIT.2019.8834609
JO  - 2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT)
Y1  - 13-15 March 2019
AB  - One of an important process in Software Quality Assurance (SQA) is software testing. One of quality assurance process done to e-Learning software is regression testing. Regression testing is done whenever a change to the e-Learning software is taken to ensure that the changes have not introduced unintended side effects by re-testing all the feature of the e-Learning software. It is important and must be done. However, the current regression testing is conducted in manual testing. The manual execution is time-consuming, not reusable, and prone to tester error due to the repetitive testing process. To overcome this problem, an automated test suite is developed to enhance the regression testing process of e-Learning software. An automated test suite that consists of 17 automated tests and able to make test reports automatically have been developed. Based on the evaluation and analysis, the automated tests have a consistent repeatability capability with test step reusability level of 68,73 and 100% success rate of execution.
ER  - 

TY  - CONF
TI  - A Model-Based Approach to Generate Dynamic Synthetic Test Data
T2  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
SP  - 495
EP  - 497
AU  - C. Tan
PY  - 2019
DO  - 10.1109/ICST.2019.00063
JO  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
Y1  - 22-27 April 2019
AB  - Having access to high-quality test data is an important requirement to ensure effective cross-organizational integration testing. The common practice for addressing this need is to generate synthetic data. However, existing approaches cannot generate representative datasets that can evolve to allow the simulation of the dynamics of the systems under test. In this PhD project, and in collaboration with an industrial partner, we investigate the use of machine learning techniques for developing novel solutions that can generate synthetic, dynamic and representative test data.
ER  - 

TY  - CONF
TI  - Poster: EBFL-An Ensemble Classifier based Fault Localization
T2  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 473
EP  - 476
AU  - A. Dutta
PY  - 2022
DO  - 10.1109/ICST53961.2022.00059
JO  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 4-14 April 2022
AB  - Fault localization (FL) is the most arduous and timeconsuming task during software debugging. It is delineated in the literature that different FL methods show superior results under distinct scenarios. There is no single technique available that always outperforms all other existing FL techniques for each type of fault. It has also been reported that different learning techniques can be combined using an ensemble classifier to generate better predictive performance that was impossible to be obtained with any of the constituent learning algorithms separately. This has motivated us to use an ensemble classifier for effective fault localization. We focus on three different families of fault localization techniques, viz., neural-network-based(NNBFL), mutation-based(MBFL), and spectrum-based(SBFL), to achieve this. In total, we have considered eleven representative techniques from these three families of FL methods. The proposed underlying model is intuitive and simple as it is based only on the test execution results and statement coverage data. Our proposed Ensemble classifier Based FL (EBFL) method classifies the statements into two different sets viz., Non-Suspicious and Suspicious. It helps to reduce the search space significantly. Our experimental analysis shows that our proposed EBFL technique requires, on average, 58% of less code examination compared to the other contemporary fault localization techniques, viz., Tarantula, DStar, CNN, DNN etc.
ER  - 

TY  - CONF
TI  - Predicted of Software Fault Based on Random Forest and K-Nearest Neighbor
T2  - 2022 4th International Conference on Advanced Science and Engineering (ICOASE)
SP  - 43
EP  - 48
AU  - M. Z. Mohammed
AU  - I. A. Saleh
PY  - 2022
DO  - 10.1109/ICOASE56293.2022.10075596
JO  - 2022 4th International Conference on Advanced Science and Engineering (ICOASE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 4th International Conference on Advanced Science and Engineering (ICOASE)
Y1  - 21-22 Sept. 2022
AB  - Software systems have gotten increasingly complicated and adaptable in today's computer world. As a result, it's critical to track down and fix software design flaws on a regular basis. Software fault prediction in early phase is useful for enhancing software quality and for reducing software testing time and expense; it's a technique for predicting problems using historical data. To anticipate software flaws from historical databases, several machine learning approaches are applied. This paper focuses on creating a predictor to predict software defects, Based on previous data. For this purpose, a supervised machine learning techniques was utilized to forecast future software failures, K-Nearest Neighbor (KNN) and Random Forest (RF) applied technique applied to the defective data set belonging to the NASA's PROMISE repository. Also, a set of performance measures such as accuracy, precision, recall and f1 measure were used to evaluate the performance of the models. This paper showed a good performance of the RF model compared to the KNN model resulting in a maximum and minimum accuracy are 99%,88% on the MC1 and KC1 responsibly. In general, the study's findings suggest that software defect metrics may be used to determine the problematic module, and that the RF model can be used to anticipate software errors.
ER  - 

TY  - CONF
TI  - A Redesigned Educational System for the COVID-19 Pandemic and Post Pandemic era
T2  - 2022 IEEE Learning with MOOCS (LWMOOCS)
SP  - 78
EP  - 83
AU  - H. Ehtesham
AU  - A. Khelifi
AU  - R. Fatima
AU  - S. Faizan
AU  - H. M. Ismail
PY  - 2022
DO  - 10.1109/LWMOOCS53067.2022.9927872
JO  - 2022 IEEE Learning with MOOCS (LWMOOCS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 IEEE Learning with MOOCS (LWMOOCS)
Y1  - 29-30 Sept. 2022
AB  - This research aims to develop a technology-driven educational application that will be a platform for providing interesting content to students. In light of the COVID-19 pan-demic, the objective of this redesign is to address the shortcomings of the current teaching strategy. In addition, survey and interview results supported the need for a revision of the current educational strategy. The proposed application employs Bloom's taxonomy quizzes to create a customized learning technique and structure content so that students can comprehend subjects more thoroughly. Visual Studio Code and the Ionic Framework were used for front-end development, while the Angular and PHP frameworks were utilized for the back-end. The program was reviewed using white box testing techniques and received positive feedback from users. In addition, it highlighted the possibility for sophisticated enhancements, such as the incorporation of learning styles, to improve the learning experiences of students.
ER  - 

TY  - CONF
TI  - Empirical evaluation of the active learning strategies on software defects prediction
T2  - 2020 6th International Symposium on System and Software Reliability (ISSSR)
SP  - 83
EP  - 89
AU  - W. Mi
AU  - Y. Li
AU  - S. Wang
PY  - 2020
DO  - 10.1109/ISSSR51244.2020.00021
JO  - 2020 6th International Symposium on System and Software Reliability (ISSSR)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 6th International Symposium on System and Software Reliability (ISSSR)
Y1  - 24-25 Oct. 2020
AB  - Software defect prediction is a popular technical method in software engineering. In order to reduce the cost of a software defects, problems existing in the software are found by testing software products. Software defect prediction often uses machine learning techniques to improve the performance of software testing but requires enough labeled data when training the model. Because the cost of obtaining data is different from the label, the data is easy to obtain, but the label is cumbersome and expensive. In order to demonstrate software defect prediction, after the data obtained active learning algorithm is introduced to query the data, and the most valuable data is selected for expert annotation and then put into the model for training. However, it is not clear which active learning query strategy to choose the most effective in the software defect prediction model. We use different active learning strategy software defect prediction models for comparison. Experiment on the NASA dataset, using Naive Bayes and SVM, Linear Regression as the classifier. Comprehensive research results show that the Density-weighted strategy has a significant effect on the data set.
ER  - 

TY  - JOUR
TI  - Scalable Mutation Testing Using Predictive Analysis of Deep Learning Model
T2  - IEEE Access
SP  - 158264
EP  - 158283
AU  - M. R. Naeem
AU  - T. Lin
AU  - H. Naeem
AU  - F. Ullah
AU  - S. Saeed
PY  - 2019
DO  - 10.1109/ACCESS.2019.2950171
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 7
VL  - 7
JA  - IEEE Access
Y1  - 2019
AB  - Software testing plays a crucial role in ensuring the quality of software systems. Mutation testing is designed to measure the adequacy of test suites by detecting artificially induced software faults. Despite their potential, the expensive cost and the scalability of mutation testing with large programs is a big obstacle in its practical use. The selective mutation has been widely investigated and considered to be an effective approach to reduce the cost of mutation testing. In the case of large programs where source code has hundreds of classes and more than 10 KLOC lines of code, the selective mutation can still generate thousands of mutants. Executing each mutant against the test suite is cost-intensive in terms of robustness, resource usage, and computational cost. In this paper, we introduce a new approach to extract features from mutant programs based on mutant killing conditions, i.e. reachability, necessity and sufficiency along with mutant significance and test suite metrics to extract features from mutant programs. A deep learning Keras model is proposed to predict killed and alive mutants from each program. First, the features are extracted using the Eclipse JDT library and program dependency analysis. Second, preprocessing techniques such as Principal Component Analysis and Synthetic Minority Oversampling are used to reduce the high dimensionality of data and to overcome the imbalanced class problem respectively. Lastly, the deep learning model is optimized using fine-tune parameters such as dropout and dense layers, activation function, error and loss rate respectively. The proposed work is analyzed on five opensource programs from GitHub repository consisting of thousands of classes and LOC. The experimental results are appreciable in terms of effectiveness and scalable mutation testing with a slight loss of accuracy.
ER  - 

TY  - CONF
TI  - An AI Software Test Method Based on Scene Deductive Approach
T2  - 2018 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)
SP  - 14
EP  - 20
AU  - X. Zhao
AU  - X. Gao
PY  - 2018
DO  - 10.1109/QRS-C.2018.00017
JO  - 2018 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)
Y1  - 16-20 July 2018
AB  - Artificial intelligence (AI) software has high algorithm complexity, and the scale and dimension of the input and output parameters are high, and the test oracle isn't explicit. These features make a lot of difficulties for the design of test cases. This paper proposes an AI software testing method based on scene deductive approach. It models the input, output parameters and the environment, uses the random algorithm to generate the inputs of the test cases, then use the algorithm of deductive approach to make the software testing automatically, and use the test assertions to verify the results of the test. After description of the theory, this paper uses intelligent tracking car as an example to illustrate the application of this method and the problems needing attention. In the end, the paper describes the shortcoming of this method and the future research directions.
ER  - 

TY  - CONF
TI  - Regression Testing Prioritization Technique Based on Historical Execution Information
T2  - 2022 International Conference on Machine Learning, Cloud Computing and Intelligent Mining (MLCCIM)
SP  - 276
EP  - 281
AU  - R. Chen
AU  - Z. Xiao
AU  - L. Xiao
AU  - Z. Li
PY  - 2022
DO  - 10.1109/MLCCIM55934.2022.00054
JO  - 2022 International Conference on Machine Learning, Cloud Computing and Intelligent Mining (MLCCIM)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 International Conference on Machine Learning, Cloud Computing and Intelligent Mining (MLCCIM)
Y1  - 5-7 Aug. 2022
AB  - Regression testing is a very important and effective testing method in the software life cycle, and its cost accounts for about 70% of the cost of software testing. Typically, regression testing re-runs all existing test cases in a random order, but this is sometimes not feasible because it leads to high test resource consumption and long feedback cycles. In this paper, we focus on how to obtain and prioritize test cases with a high fault detection rate based on historical execution information. Secondly, how to improve the efficiency of priority technology based on historical data in continuous integration. We implemented a series of experiments using three industrial datasets. The experimental results show that the prioritisation techniques based on average historical failure rates and average historical execution failure rates outperform other techniques; If historical execution information is insufficient, techniques that integrate historical execution information with requirements priorities provide better performance.
ER  - 

TY  - CONF
TI  - ISSRE 2020 Doctoral Symposium Keynote: How to Get Your Paper Rejected
T2  - 2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
SP  - xxvi
EP  - xxvii
AU  - J. Offutt
PY  - 2020
DO  - 10.1109/ISSREW51248.2020.00010
JO  - 2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
Y1  - 12-15 Oct. 2020
AB  - My papers have been rejected nearly a thousand times (including by ISSRE 2020). In fact, being rejected is one of my best skills! I am confident that I lead the field of software testing in the number of rejections. In this talk, I try to pass on my knowledge and skills to a younger generation, so that you, too, can aspire to accumulate large piles of rejection messages.
ER  - 

TY  - CONF
TI  - Importance-Driven Deep Learning System Testing
T2  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
SP  - 322
EP  - 323
AU  - S. Gerasimou
AU  - H. F. Eniser
AU  - A. Sen
AU  - A. Cakan
PY  - 2020
DO  - 
JO  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
IS  - 
SN  - 2574-1926
VO  - 
VL  - 
JA  - 2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
Y1  - 5-11 Oct. 2020
AB  - Deep Learning (DL) systems are key enablers for engineering intelligent applications. Nevertheless, using DL systems in safety- and security-critical applications requires to provide testing evidence for their dependable operation. We introduce DeepImportance, a systematic testing methodology accompanied by an Importance-Driven (IDC) test adequacy criterion for DL systems. Applying IDC enables to establish a layer-wise functional understanding of the importance of DL system components and use this information to assess the semantic diversity of a test set. Our empirical evaluation on several DL systems and across multiple DL datasets demonstrates the usefulness and effectiveness of DeepImportance.
ER  - 

TY  - CONF
TI  - Development Model of Warteg Online Applications based on Web and Mobile
T2  - 2020 International Conference on Information Management and Technology (ICIMTech)
SP  - 864
EP  - 869
AU  - J. W. Ivanovich
AU  - M. A. Said
AU  - S. A. Rohim
AU  - M. R. Wicaksono
AU  - E. H. Yossy
PY  - 2020
DO  - 10.1109/ICIMTech50083.2020.9211263
JO  - 2020 International Conference on Information Management and Technology (ICIMTech)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 International Conference on Information Management and Technology (ICIMTech)
Y1  - 13-14 Aug. 2020
AB  - The development of software engineering as well as mobile and web-apps has enabled the modernization of businesses such as warung tegal (warteg). The purpose of this research is to design an online warteg application. Application development uses the method of developing system development life cycle with the waterfall model. This application was built using the Native React Framework and with the PostgreSQL Database. The expected result is the design of online warteg applications that can be accessed on websites and mobile phones that can help warteg entrepreneurs to facilitate the promotion and sale of merchandise they sell, as well as to facilitate the public to buy food without having to come to the warteg.
ER  - 

TY  - CONF
TI  - Aging Related Bug Prediction using Extreme Learning Machines
T2  - 2017 14th IEEE India Council International Conference (INDICON)
SP  - 1
EP  - 6
AU  - L. Kumar
AU  - A. Sureka
PY  - 2017
DO  - 10.1109/INDICON.2017.8487925
JO  - 2017 14th IEEE India Council International Conference (INDICON)
IS  - 
SN  - 2325-9418
VO  - 
VL  - 
JA  - 2017 14th IEEE India Council International Conference (INDICON)
Y1  - 15-17 Dec. 2017
AB  - Aging-Related Bugs (ARBs) occur in long running systems due to error conditions caused because of accumulation of problems such as memory leakage or unreleased files and locks. Aging-Related Bugs are hard to discover during software testing and also challenging to replicate. Automatic identification and prediction of aging related fault-prone files and classes in an object oriented system can help the software quality assurance team to optimize their testing efforts. In this paper, we present a study on the application of static source code metrics and machine learning techniques to predict aging related bugs. We conduct a series of experiments on publicly available dataset from two large open-source software systems: Linux and MySQL. Class imbalance and high dimensionality are the two main technical challenges in building effective predictors for aging related bugs. We investigate the application of five different feature selection techniques (OneR, Information Gain, Gain Ratio, RELEIF and Symmetric Uncertainty) for dimensionality reduction and SMOTE method to counter the effect of class imbalance in our proposed machine learning based solution approach. We apply Extreme Learning Machines (ELM) with three different kernels (linear, polynomial and RBF) and present experimental results which demonstarte the effectiveness of our approach.
ER  - 

TY  - CONF
TI  - Effectiveness of dataset reduction in testing machine learning algorithms
T2  - 2020 IEEE International Conference On Artificial Intelligence Testing (AITest)
SP  - 133
EP  - 140
AU  - J. Chandrasekaran
AU  - H. Feng
AU  - Y. Lei
AU  - R. Kacker
AU  - D. R. Kuhn
PY  - 2020
DO  - 10.1109/AITEST49225.2020.00027
JO  - 2020 IEEE International Conference On Artificial Intelligence Testing (AITest)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE International Conference On Artificial Intelligence Testing (AITest)
Y1  - 3-6 Aug. 2020
AB  - Many machine learning algorithms examine large amounts of data to discover insights from hidden patterns. Testing these algorithms can be expensive and time-consuming. There is a need to speed up the testing process, especially in an agile development process, where testing is frequently performed. One approach is to replace big datasets with smaller datasets produced by random sampling. In this paper, we report a set of experiments that are designed to evaluate the effectiveness of using reduced datasets produced by random sampling for testing machine learning algorithms. In our experiments, we use as subject programs four supervised learning algorithms from the Waikato Environment for Knowledge Analysis (WEKA). We identify five datasets from Kaggle.com to run with the four learning algorithms. For each dataset, we generate reduced datasets of different sizes using two random sampling strategies, i.e., pure random and stratified random sampling. We execute our subject programs with the original and the reduced datasets, and measure test effectiveness using branch and mutation coverage. Our results indicate that in most cases, reduced datasets of even very small sizes can achieve the same or similar coverage achieved by the original dataset. Furthermore, our results indicate that reduced datasets produced by the two sample strategies do not differ significantly, and branch coverage correlates with mutation coverage.
ER  - 

TY  - CONF
TI  - Applying an Instructional Design Process to Development of an Independent Verification and Validation Training Program
T2  - 2016 IEEE 29th International Conference on Software Engineering Education and Training (CSEET)
SP  - 237
EP  - 240
AU  - N. Okubo
AU  - K. Nara
AU  - S. Takemura
AU  - Y. Ueda
PY  - 2016
DO  - 10.1109/CSEET.2016.17
JO  - 2016 IEEE 29th International Conference on Software Engineering Education and Training (CSEET)
IS  - 
SN  - 2377-570X
VO  - 
VL  - 
JA  - 2016 IEEE 29th International Conference on Software Engineering Education and Training (CSEET)
Y1  - 5-6 April 2016
AB  - This paper describes the experience of developing Independent Verification and Validation (IV&V) training programby applying an Instructional Design Process(IDP). This is not complete training to become an IV&V engineer, but job training to help solve common problems encountered in IV&V work. The instructional design process featured extensive frontend analysis before the design and implementation of the instruction, and also repeated revision of the instruction. The Dick and Carey model influenced the process used for developing the IV&V training program, which we called J-IDP. We conducted a field trial with the entry level of the training materials, but the resultwas not as positive as expected. Therefore, following J-IDP, we reviewed the materials and revised the training. Our experience with this training program suggests applying an instructional design process may solve some aspects of two common issues for software engineering education or training, the difficulty in identifying necessary abilities for software engineers and the difficulty in maintaining the training up-to-date.
ER  - 

TY  - CONF
TI  - Inferring Automatic Test Oracles
T2  - 2017 IEEE/ACM 10th International Workshop on Search-Based Software Testing (SBST)
SP  - 5
EP  - 6
AU  - W. B. Langdon
AU  - S. Yoo
AU  - M. Harman
PY  - 2017
DO  - 10.1109/SBST.2017.1
JO  - 2017 IEEE/ACM 10th International Workshop on Search-Based Software Testing (SBST)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2017 IEEE/ACM 10th International Workshop on Search-Based Software Testing (SBST)
Y1  - 22-23 May 2017
AB  - We propose the use of search based learning from existing open source test suitesto automatically generate partially correct test oracles. We argue that mutation testing and n-version computing(augmented by deep learningand other soft computingtechniques), will be able to predict whether a program's output is correct sufficiently accurately to be useful.
ER  - 

TY  - CONF
TI  - Construction of GUI Elements Recognition Model for AI Testing based on Deep Learning
T2  - 2021 8th International Conference on Dependable Systems and Their Applications (DSA)
SP  - 508
EP  - 515
AU  - C. Zhang
AU  - T. Shi
AU  - J. Ai
AU  - W. Tian
PY  - 2021
DO  - 10.1109/DSA52907.2021.00075
JO  - 2021 8th International Conference on Dependable Systems and Their Applications (DSA)
IS  - 
SN  - 2767-6684
VO  - 
VL  - 
JA  - 2021 8th International Conference on Dependable Systems and Their Applications (DSA)
Y1  - 5-6 Aug. 2021
AB  - Nowadays, GUI testing ensures the quality of GUI software. GUI automated testing by recording coordinates and handles has the disadvantages of poor reusability and low portability, which reduces the quality of GUI software testing. Therefore, GUI testing needs a more efficient testing to meet the rapid development of GUI software. AI can make testing more efficient. But the precondition of GUI software testing is to identify the GUI elements. In this context, the present paper studies the intelligent recognition of GUI elements based on deep learning, develops uniform markup rules for GUI elements and creates datasets to train the GUI element recognition model. According to the selected object detection network, the GUI element recognition model is trained, and the results are analyzed and discussed. The results of this project not only provide technical support for GUI intelligent testing, but also provide research objects and data for intelligent system reliability.
ER  - 

TY  - CONF
TI  - An Empirical Comparison of Two Different Strategies to Automated Fault Detection: Machine Learning Versus Dynamic Analysis
T2  - 2019 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
SP  - 378
EP  - 385
AU  - R. Almaghairbe
AU  - M. Roper
PY  - 2019
DO  - 10.1109/ISSREW.2019.00099
JO  - 2019 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2019 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)
Y1  - 27-30 Oct. 2019
AB  - Software testing is an established method to ensure software quality and reliability, but it is an expensive process. In recent years, the automation of test case generation has received significant attention as a way to reduce costs. However, the oracle problem (a mechanism for determine the (in) correctness of an executed test case) is still major problem which has been largely ignored. Recent work has shown that building a test oracle using the principles of anomaly detection techniques (mainly semisupervised/ unsupervised learning models based on dynamic execution data consisting of an amalgamation of input/output pairs and execution traces) is able to demonstrate a reasonable level of success in automatically detect passing and failing execution [1], [2]. In this paper, we present a comparison study between our machine-learning based approaches and an existing techniques from the specification mining domain (the data invariant detector Daikon [3]). The two approaches are evaluated on a range of midsized systems and compared in terms of their fault detection ability. The results show that in most cases semi-supervised learning techniques perform far better as an automated test classifier than Daikon. However, there is one system for which our strategy struggles and Daikon performed far better. Furthermore, unsupervised learning techniques performed on a par when compared with Daikon in several cases.
ER  - 

TY  - JOUR
TI  - Test Case Prioritization Using Firefly Algorithm for Software Testing
T2  - IEEE Access
SP  - 132360
EP  - 132373
AU  - M. Khatibsyarbini
AU  - M. A. Isa
AU  - D. N. A. Jawawi
AU  - H. N. A. Hamed
AU  - M. D. Mohamed Suffian
PY  - 2019
DO  - 10.1109/ACCESS.2019.2940620
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 7
VL  - 7
JA  - IEEE Access
Y1  - 2019
AB  - Software testing is a vital and complex part of the software development life cycle. Optimization of software testing is still a major challenge, as prioritization of test cases remains unsatisfactory in terms of Average Percentage of Faults Detected (APFD) and time execution performance. This is attributed to a large search space to find an optimal ordering of test cases. In this paper, we have proposed an approach to prioritize test cases optimally using Firefly Algorithm. To optimize the ordering of test cases, we applied Firefly Algorithm with fitness function defined using a similarity distance model. Experiments were carried on three benchmark programs with test suites extracted from Software-artifact Infrastructure Repository (SIR). Our Test Case Prioritization (TCP) technique using Firefly Algorithm with similarity distance model demonstrated better if not equal in terms of APFD and time execution performance compared to existing works. Overall APFD results indicate that Firefly Algorithm is a promising competitor in TCP applications.
ER  - 

TY  - CONF
TI  - Tool Support for Refactoring Manual Tests
T2  - 2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)
SP  - 332
EP  - 342
AU  - E. BERNARD
AU  - J. BOTELLA
AU  - F. AMBERT
AU  - B. LEGEARD
AU  - M. UTTING
PY  - 2020
DO  - 10.1109/ICST46399.2020.00041
JO  - 2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)
Y1  - 24-28 Oct. 2020
AB  - Manual test suites are typically described by natural language, and over time large manual test suites become disordered and harder to use and maintain. This paper focuses on the challenge of providing tool support for refactoring such test suites to make them more usable and maintainable. We describe how we have applied various machine-learning and NLP techniques and other algorithms to the refactoring of manual test suites, plus the tool support we have built to embody these techniques and to allow test suites to be explored and visualised. We evaluate our approach on several industry test suites, and report on the time savings that were obtained.
ER  - 

TY  - CONF
TI  - Assessing Technical Debt in Automated Tests with CodeScene
T2  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 122
EP  - 125
AU  - A. Tornhill
PY  - 2018
DO  - 10.1109/ICSTW.2018.00039
JO  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 9-13 April 2018
AB  - Test automation promises several advantages such as shorter lead times, higher code quality, and an executable documentation of the system's behavior. However, test automation won't deliver on those promises unless the quality of the automated test code itself is maintained, and to manually inspect the evolution of thousands of tests that change on a daily basis is impractical at best. This paper investigates how CodeScene - a tool for predictive analyses and visualizations - could be used to identify technical debt in automated test code. CodeScene combines repository mining, static code analysis, and machine learning to prioritize potential code improvements based on the most likely return on investment.
ER  - 

TY  - CONF
TI  - Software and System Reliability Engineering for Autonomous Systems Incorporating Machine Learning
T2  - 2020 Annual Reliability and Maintainability Symposium (RAMS)
SP  - 1
EP  - 6
AU  - A. Gula
AU  - C. Ellis
AU  - S. Bhattacharya
AU  - L. Fiondella
PY  - 2020
DO  - 10.1109/RAMS48030.2020.9153595
JO  - 2020 Annual Reliability and Maintainability Symposium (RAMS)
IS  - 
SN  - 2577-0993
VO  - 
VL  - 
JA  - 2020 Annual Reliability and Maintainability Symposium (RAMS)
Y1  - 27-30 Jan. 2020
AB  - Artificial intelligence and machine learning have attracted significant interest as enablers of autonomous systems. However, these techniques are susceptible to a variety of failures as well as adversarial attacks, suggesting the need for formal reliability and resilience engineering methods. Tempered by the knowledge that machine learning is not a panacea and that private industry, infrastructure management, and defense systems are regularly subject to external attack, it is essential to assess the possible failures and corresponding consequences that these technologies may inadvertently introduce. This paper seeks to bridge the gap between traditional and emerging methods to support the engineering of autonomous systems incorporating machine learning. Toward this end we seek to synthesize methods from established fields such as system and reliability engineering as well as software testing with recent trends in the design and test of machine learning algorithms. The proposed approach should provide organizations with additional structure to comprehend and allocate their risk mitigation efforts in order to address issues that will inevitably arise from these less well understood technologies.
ER  - 

TY  - JOUR
TI  - The Inadequacy of Discrete Scenarios in Assessing Deep Neural Networks
T2  - IEEE Access
SP  - 118236
EP  - 118242
AU  - T. Ken Mori
AU  - X. Liang
AU  - L. Elster
AU  - S. Peters
PY  - 2022
DO  - 10.1109/ACCESS.2022.3220904
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 10
VL  - 10
JA  - IEEE Access
Y1  - 2022
AB  - Many recent approaches for automated driving (AD) functions currently include components relying on deep neural networks (DNNs). One approach in order to test AD functions is the scenario-based approach. This work formalizes and evaluates the parameter discretization process required in order to yield concrete scenarios for which an AD function can be tested. Using a common perception algorithm for camera images, a simulation case study is conducted for a simple static scenario containing one other vehicle. The results are analyzed with methods akin to those applied in the domain of computational fluid dynamics (CFD). The performance of the perception algorithm shows strong fluctuations even for small input changes and displays unpredictable outliers even at very small discretization steps. The convergence criteria as known from CFD fail, meaning that no parametrization is found which is sufficient for the validation of the perception component. Indeed, the results do not indicate consistent improvement with a finer discretization. These results agree well with theoretical attributes known for existing neural networks. However, the impact appears to be large even for the most basic scenario without malicious input. This indicates the necessity of directing more attention towards the parameter discretization process of the scenario-based testing approach to enable the safety argumentation of AD functions.
ER  - 

TY  - CONF
TI  - Autonomous GUI Testing using Deep Reinforcement Learning
T2  - 2021 17th International Computer Engineering Conference (ICENCO)
SP  - 94
EP  - 100
AU  - S. Saber
AU  - F. Elbadry
AU  - H. Negm
AU  - R. A. El-Ershad
AU  - O. Magdy
AU  - M. Bahnassawi
AU  - R. El Adawi
AU  - A. Bayoumi
PY  - 2021
DO  - 10.1109/ICENCO49852.2021.9715282
JO  - 2021 17th International Computer Engineering Conference (ICENCO)
IS  - 
SN  - 2475-2320
VO  - 
VL  - 
JA  - 2021 17th International Computer Engineering Conference (ICENCO)
Y1  - 29-30 Dec. 2021
AB  - Automating software testing looks forward to speeding up testing processes and ensuring possible replication of discovered software bugs. However, Automating the GUI testing process is highly challenging due to the need for human intervention to determine actions and assess outcomes. We introduce a novel approach to fully automate GUI testing using deep reinforcement learning. Our deep reinforcement learning model discovers all system states and determines possible testing sequences. The automated testing agent starts with exploring the tested environment to learn the most efficient paths for reaching maximum coverage while discovering GUI bugs. In this case, testers could focus more on functionality testing to improve the overall software quality. We evaluated the developed model on a couple of industry products, and it showed a substantial increase in coverage than random testing.
ER  - 

TY  - CONF
TI  - Code Defenders: A Mutation Testing Game
T2  - 2016 IEEE Ninth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 162
EP  - 167
AU  - J. M. Rojas
AU  - G. Fraser
PY  - 2016
DO  - 10.1109/ICSTW.2016.43
JO  - 2016 IEEE Ninth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 IEEE Ninth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 11-15 April 2016
AB  - Mutation testing is endorsed by software testing researchers for its unique capability of providing pragmatic estimates of a test suite's fault detection capability, and for guiding testers in improving their test suites. In practice, however, wide-spread adoption of mutation testing is hampered because any non-trivial program results in huge numbers of mutants, many of which are either trivial or equivalent, and thus useless. Trivial mutants reduce the motivation of developers in trusting and using the technique, while equivalent mutants are frustratingly difficult to handle. These problems are exacerbated by insufficient education on testing, which often means that mutation testing is not well understood in practice. These are examples of the types of problems that gamification aims to overcome by making such tedious activities competitive and entertaining. In this paper, we introduce the first steps towards building Code Defenders, a mutation testing game where players take the role of an attacker, who aims to create the most subtle non-equivalent mutants, or a defender, who aims to create strong tests to kill these mutants. The benefits of such an approach are manifold: The game can serve an educational role by engaging learners in mutation testing activities in a fun way. Experienced players will produce strong test suites, capable of detecting even the most subtle bugs that other players can conceive. Equivalent mutants are handled by making them a special part of the gameplay, where points are at stake in duels between attackers and defenders.
ER  - 

TY  - CONF
TI  - A Method and Experiment to evaluate Deep Neural Networks as Test Oracles for Scientific Software
T2  - 2022 IEEE/ACM International Conference on Automation of Software Test (AST)
SP  - 40
EP  - 51
AU  - V. A. de Santiago Júnior
PY  - 2022
DO  - 10.1145/3524481.3527232
JO  - 2022 IEEE/ACM International Conference on Automation of Software Test (AST)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 IEEE/ACM International Conference on Automation of Software Test (AST)
Y1  - 21-22 May 2022
AB  - Testing scientific software is challenging because usually such type of systems have non-deterministic behaviours and, in addition, they generate non-trivial outputs such as images. Artificial intelligence (AI) is now a reality which is also helping in the development of the software testing activity. In this article, we evaluate seven deep neural networks (DNNs), precisely deep convolutional neural networks (CNNs) with up to 161layers, playing the role of test oracle procedures for testing scientific models. Firstly, we propose a method, TOrC, which starts by generating training, validation, and test image datasets via combinatorial interaction testing applied to the original codes and second-order mutants. Within TOrC we also have classical steps such as transfer learning, a technique recommended for DNNs. Then, we verified the performance of the oracles (CNNs). The main conclusions of this research are: i) not necessarily a greater number of layers means that a CNN will present better performance; ii) transfer learning is a valuable technique but eventually we may need extended solutions to get better performances; iii) data-centric AI is an interesting path to follow; and iv) there is not a clear correlation between the software bugs, in the scientific models, and the errors (image misclassifications) presented by the CNNs. CCS CONCEPTS • Software and its engineering → Software testing and debugging;. Computing methodologies → Neural networks; Supervised learning by classification; Computer vision.
ER  - 

TY  - CONF
TI  - Test Automation: From Slow & Weak to Fast, Flaky, & Blind to Smart & Effective
T2  - 2023 IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 11
EP  - 11
AU  - J. Offutt
PY  - 2023
DO  - 10.1109/ICST57152.2023.00009
JO  - 2023 IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2023 IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 16-20 April 2023
AB  - All technical fields add more automation over time as we replace human labor with innovative technologies. Automation comes with many advantages: It creates research opportunities, offers savings in practice, and reduces errors. Automation also comes with disruptive costs. Processes must change to accommodate the automation, and human laborers must adapt by learning new knowledge and skills. Automation also evolves over time as advances inspire more new ideas for automation. This presentation will reflect on automation through history and on years of experience inventing ways to automate software testing. The talk will review achievements in test automation, discuss challenges in cutting edge domains such as games and AI, and present open problems for future research and for practical applications.
ER  - 

TY  - CONF
TI  - Lessons learnt from using DSLs for automated software testing
T2  - 2015 IEEE Eighth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 1
EP  - 6
AU  - M. Micallef
AU  - C. Colombo
PY  - 2015
DO  - 10.1109/ICSTW.2015.7107472
JO  - 2015 IEEE Eighth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2015 IEEE Eighth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 13-17 April 2015
AB  - Domain Specific Languages (DSLs) provide a means of unambiguously expressing concepts in a particular domain. Although they may not refer to it as such, companies build and maintain DSLs for software testing on a day-to-day basis, especially when they define test suites using the Gherkin language. However, although the practice of specifying and automating test cases using the Gherkin language and related technologies such as Cucumber has become mainstream, the curation of such languages presents a number of challenges. In this paper we discuss lessons learnt from five case studies on industry systems, two involving the use of Gherkin-type syntax and another three case studies using more rigidly defined language grammars. Initial observations indicate that the likelihood of success of such efforts is increased if one manages to use an approach which separates the concerns of domain experts who curate the language, users who write scripts with the language, and engineers who wire the language into test automation technologies thus producing executable test code. We also provide some insights into desirable qualities of testing DSLs in different contexts.
ER  - 

TY  - CONF
TI  - Software fault prediction based on one-class SVM
T2  - 2016 International Conference on Machine Learning and Cybernetics (ICMLC)
SP  - 1003
EP  - 1008
AU  - L. Chen
AU  - B. Fang
AU  - Z. Shang
PY  - 2016
DO  - 10.1109/ICMLC.2016.7873016
JO  - 2016 International Conference on Machine Learning and Cybernetics (ICMLC)
IS  - 
SN  - 2160-1348
VO  - 2
VL  - 2
JA  - 2016 International Conference on Machine Learning and Cybernetics (ICMLC)
Y1  - 10-13 July 2016
AB  - Software fault prediction (SFP) is useful for helping the software engineer to locate potential faulty modules in software testing more easily, so that it can save a lot of time and budgets to improve the software quality. In this paper, aiming at solving the problem that the faulty samples are too rare to train a classifier, an one-class SFP model is proposed by using only non-faulty samples based on one-class SVM. The empirical validation is conducted on 6 extremely imbalanced datasets collected from real-world software containing only small amounts of faulty instances. The test results suggest that the proposed model can achieve a reasonable fault prediction performance when using only a small proportion of training samples, and performs much better than conventional and class imbalanced learning based SFP models in terms of G-mean measure. Thus the proposed model provided a considerable solution for SFP with a few faulty modules in early life of software testing.
ER  - 

TY  - JOUR
TI  - Test Better by Exploring: Harnessing Human Skills and Knowledge
T2  - IEEE Software
SP  - 90
EP  - 96
AU  - J. Itkonen
AU  - M. V. Mäntylä
AU  - C. Lassenius
PY  - 2016
DO  - 10.1109/MS.2015.85
JO  - IEEE Software
IS  - 4
SN  - 1937-4194
VO  - 33
VL  - 33
JA  - IEEE Software
Y1  - July-Aug. 2016
AB  - Users continue to stumble upon software bugs, despite developers' efforts to build and test high-quality software. Although traditional testing and quality assurance techniques are extremely valuable, software testing should pay more attention to exploration. Exploration can directly apply knowledge and learning to the core of industrial software testing, revealing more relevant bugs earlier. This article describes exploration's characteristics, knowledge's role in software testing, and the three levels of exploratory-testing practices. Academics and practitioners should focus on exploiting exploration's strengths in software testing and on reporting existing practices and benefits in different academic and industrial contexts.
ER  - 

TY  - JOUR
TI  - Constrained Interaction Testing: A Systematic Literature Study
T2  - IEEE Access
SP  - 25706
EP  - 25730
AU  - B. S. Ahmed
AU  - K. Z. Zamli
AU  - W. Afzal
AU  - M. Bures
PY  - 2017
DO  - 10.1109/ACCESS.2017.2771562
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 5
VL  - 5
JA  - IEEE Access
Y1  - 2017
AB  - Interaction testing can be used to effectively detect faults that are otherwise difficult to find by other testing techniques. However, in practice, the input configurations of software systems are subjected to constraints, especially in the case of highly configurable systems. Handling constraints effectively and efficiently in combinatorial interaction testing is a challenging problem. Nevertheless, researchers have attacked this challenge through different techniques, and much progress has been achieved in the past decade. Thus, it is useful to reflect on the current achievements and shortcomings and to identify potential areas of improvements. This paper presents the first comprehensive and systematic literature study to structure and categorize the research contributions for constrained interaction testing. Following the guidelines of conducting a literature study, the relevant data are extracted from a set of 103 research papers belonging to constrained interaction testing. The topics addressed in constrained interaction testing research are classified into four categories of constraint test generation, application, generation and application, and model validation studies. The papers within each of these categories are extensively reviewed. Apart from answering several other research questions, this paper also discusses the applications of constrained interaction testing in several domains, such as software product lines, fault detection and characterization, test selection, security, and graphical user interface testing. This paper ends with a discussion of limitations, challenges, and future work in the area.
ER  - 

TY  - CONF
TI  - Applying Automated Test Case Generation in Industry: A Retrospective
T2  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 364
EP  - 369
AU  - R. Ramler
AU  - C. Klammer
AU  - G. Buchgeher
PY  - 2018
DO  - 10.1109/ICSTW.2018.00074
JO  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 9-13 April 2018
AB  - Automated test case generation promises to reduce the high effort of manually developing and maintaining test cases, to improve the effectiveness of testing, and to speed-up testing cycles. Research on generating test cases has advanced over the past decades and today a wide range of techniques and tools are available, including studies showing their successful evaluation in real-world scenarios. We conducted a multi-firm research project on automated software testing that involved the application of automated test case generation approaches in industry projects. This paper provides a retrospective on the related activities. It reports on our observations and insights from applying automated test case generation in practice, identifies pitfalls and gaps in current research, and summarizes lessons learned from transferring software testing research results to industry.
ER  - 

TY  - CONF
TI  - An Improved Approach to Software Defect Prediction using a Hybrid Machine Learning Model
T2  - 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)
SP  - 443
EP  - 448
AU  - D. -L. Miholca
PY  - 2018
DO  - 10.1109/SYNASC.2018.00074
JO  - 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)
Y1  - 20-23 Sept. 2018
AB  - Software defect prediction is an intricate but essential software testing related activity. As a solution to it, we have recently proposed HyGRAR, a hybrid classification model which combines Gradual Relational Association Rules (GRARs) with ANNs. ANNs were used to learn gradual relations that were then considered in a mining process so as to discover the interesting GRARs characterizing the defective and non-defective software entities, respectively. The classification of a new entity based on the discriminative GRARs was made through a non-adaptive heuristic method. In current paper, we propose to enhance HyGRAR through autonomously learning the classification methodology. Evaluation experiments performed on two open-source data sets indicate that the enhanced HyGRAR classifier outperforms the related approaches evaluated on the same two data sets.
ER  - 

TY  - JOUR
TI  - Exploring the Profiles of Software Testing Jobs in the United States
T2  - IEEE Access
SP  - 68905
EP  - 68916
AU  - M. Kassab
AU  - P. Laplante
AU  - J. Defranco
AU  - V. V. G. Neto
AU  - G. Destefanis
PY  - 2021
DO  - 10.1109/ACCESS.2021.3077755
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 9
VL  - 9
JA  - IEEE Access
Y1  - 2021
AB  - There is an indisputable industrial need for highly skilled individuals in the role of software testers. However, little is known about what activities under testers' responsibilities, competencies, and experiences sought after from employers' perspectives. For the purpose of this research, a data set of 1000 job ads related to software testing role in the United States was collected and analyzed. Specifically, a thorough analysis was conducted to find the industrial demand for competencies for the software testing role in terms of (i) Level of education, training, and experience; (ii) Testing skills; (iii) Technical skills; and (iv) Soft-skills. Relevant correlated skills that may influence shaping the profile of the software tester were also analyzed. Also, the essential duties that a software tester is expected to perform were investigated. The results from the subsequent quantitative and qualitative analysis are reported.
ER  - 

TY  - CONF
TI  - Impact of mutation intensity on evolutionary test model learning
T2  - 2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES)
SP  - 271
EP  - 276
AU  - M. Sroka
AU  - R. Nagy
AU  - D. Fisch
PY  - 2015
DO  - 10.1109/INES.2015.7329720
JO  - 2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES)
Y1  - 3-5 Sept. 2015
AB  - Automation in the software testing process has significant impact on the overall software development in industry. The focus of this paper is on automation of test case design via model-based testing for automotive embedded software. A new method based on an evolutionary algorithm for acquiring the necessary test model automatically from sample test cases and additional sources of information was designed and this paper investigates the impact of mutation intensity on the evolutionary learning process.
ER  - 

TY  - CONF
TI  - An Extensive Study on Cross-Project Predictive Mutation Testing
T2  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
SP  - 160
EP  - 171
AU  - D. Mao
AU  - L. Chen
AU  - L. Zhang
PY  - 2019
DO  - 10.1109/ICST.2019.00025
JO  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)
Y1  - 22-27 April 2019
AB  - Mutation testing is a powerful technique for evaluating the quality of test suite which plays a key role in ensuring software quality. The concept of mutation testing has also been widely used in other software engineering studies, e.g., test generation, fault localization, and program repair. During the process of mutation testing, large number of mutants may be generated and then executed against the test suite to examine whether they can be killed, making the process extremely computational expensive. Several techniques have been proposed to speed up this process, including selective, weakened, and predictive mutation testing. Among those techniques, Predictive Mutation Testing (PMT) tries to build a classification model based on an amount of mutant execution records to predict whether coming new mutants would be killed or alive without mutant execution, and can achieve significant mutation cost reduction. In PMT, each mutant is represented as a list of features related to the mutant itself and the test suite, transforming the mutation testing problem to a binary classification problem. In this paper, we perform an extensive study on the effectiveness and efficiency of the promising PMT technique under the cross-project setting using a total 654 real world projects with more than 4 Million mutants. Our work also complements the original PMT work by considering more features and the powerful deep learning models. The experimental results show an average of over 0.85 prediction accuracy on 654 projects using cross validation, demonstrating the effectiveness of PMT. Meanwhile, a clear speed up is also observed with an average of 28.7× compared to traditional mutation testing with 5 threads. In addition, we analyze the importance of different groups of features in classification model, which provides important implications for the future research.
ER  - 

TY  - CONF
TI  - Learning Realistic Mutations: Bug Creation for Neural Bug Detectors
T2  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 162
EP  - 173
AU  - C. Richter
AU  - H. Wehrheim
PY  - 2022
DO  - 10.1109/ICST53961.2022.00027
JO  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2022 IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 4-14 April 2022
AB  - Mutations are small, often token-level changes to program code, typically performed during mutation testing for evaluating the quality of test suites. Recently, code mutations have come in use for creating benchmarks of buggy code. Such bug benchmarks present valuable aids for the evaluation of testing, debugging or bug repair tools. Moreover, they can serve as training data for learning-based (neural) bug detectors. Key to all these applications is the creation of realistic bugs which closely resemble mistakes made by software developers. In this paper, we present a learning-based approach to mutation. We propose a novel contextual mutation operator which incorporates knowledge about the mutation context to inject natural and more realistic bugs into code. Our approach employs a masked language model to produce a context-dependent distribution over feasible token replacements. The strategy for producing realistic mutations is thus learned. Our experimental evaluation on Java, JavaScript and Python programs shows that sampling from a language model does not only produce mutants which more accurately represent real bugs (with a reproduction score nearly 70% higher than for mutations employed in testing), but also lead to better performing bug detectors when trained on thus generated bug benchmarks.
ER  - 

TY  - CONF
TI  - Testing Machine Learning Systems in Industry: An Empirical Study
T2  - 2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)
SP  - 263
EP  - 272
AU  - S. Li†
AU  - J. Guo†
AU  - J. -G. Lou
AU  - M. Fan
AU  - T. Liu‡
AU  - D. Zhang
PY  - 2022
DO  - 10.1145/3510457.3513036
JO  - 2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)
Y1  - 22-24 May 2022
AB  - Machine learning becomes increasingly prevalent and integrated into a wide range of software systems. These systems, named ML systems, must be adequately tested to gain confidence that they behave correctly. Although many research efforts have been devoted to testing technologies for ML systems, the industrial teams are faced with new challenges on testing the ML systems in real-world settings. To absorb inspirations from the industry on the problems in ML testing, we conducted an empirical study including a survey with 87 responses and interviews with 7 senior ML practitioners from well-known IT companies. Our study uncovers significant industrial concerns on major testing activities, i.e., test data collection, test execution, and test result analysis, and also the good practices and open challenges from the perspective of the industry. (1) Test data collection is conducted in different ways on ML model, data, and code and faced with different challenges. (2) Test execution in ML systems suffers from two major problems: entanglement among the components and the regression on model performance. (3) Test result analysis centers on quantitative methods, e.g., metric-based evaluation, and is combined with some qualitative methods based on practitioners’ experience. Based on our findings, we highlight the research opportunities and also provide some implications for practitioners.
ER  - 

TY  - CONF
TI  - A Reinforcement Learning Approach to Generating Test Cases for Web Applications
T2  - 2023 IEEE/ACM International Conference on Automation of Software Test (AST)
SP  - 13
EP  - 23
AU  - X. Chang
AU  - Z. Liang
AU  - Y. Zhang
AU  - L. Cui
AU  - Z. Long
AU  - G. Wu
AU  - Y. Gao
AU  - W. Chen
AU  - J. Wei
AU  - T. Huang
PY  - 2023
DO  - 10.1109/AST58925.2023.00006
JO  - 2023 IEEE/ACM International Conference on Automation of Software Test (AST)
IS  - 
SN  - 2833-9061
VO  - 
VL  - 
JA  - 2023 IEEE/ACM International Conference on Automation of Software Test (AST)
Y1  - 15-16 May 2023
AB  - Web applications play an important role in modern society. Quality assurance of web applications requires lots of manual efforts. In this paper, we propose WebQT, an automatic test case generator for web applications based on reinforcement learning. Specifically, to increase testing efficiency, we design a new reward model, which encourages the agent to mimic human testers to interact with the web applications. To alleviate the problem of state redundancy, we further propose a novel state abstraction technique, which can identify different web pages with the same functionality as the same state, and yields a simplified state space. We evaluate WebQT on seven open-source web applications. The experimental results show that WebQT achieves 45.4% more code coverage along with higher efficiency than the state-of-the-art technique. In addition, WebQT also reveals 69 exceptions in 11 real-world web applications.
ER  - 

TY  - CONF
TI  - Learning-Based Fuzzing of IoT Message Brokers
T2  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
SP  - 47
EP  - 58
AU  - B. K. Aichernig
AU  - E. Muškardin
AU  - A. Pferscher
PY  - 2021
DO  - 10.1109/ICST49551.2021.00017
JO  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 2159-4848
VO  - 
VL  - 
JA  - 2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)
Y1  - 12-16 April 2021
AB  - The number of devices in the Internet of Things (IoT) immensely grew in recent years. A frequent challenge in the assurance of the dependability of IoT systems is that components of the system appear as a black box. This paper presents a semi-automatic testing methodology for black-box systems that combines automata learning and fuzz testing. Our testing technique uses stateful fuzzing based on a model that is automatically inferred by automata learning. Applying this technique, we can simultaneously test multiple implementations for unexpected behavior and possible security vulnerabilities.We show the effectiveness of our learning-based fuzzing technique in a case study on the MQTT protocol. MQTT is a widely used publish/subscribe protocol in the IoT. Our case study reveals several inconsistencies between five different MQTT brokers. The found inconsistencies expose possible security vulnerabilities and violations of the MQTT specification.
ER  - 

TY  - CONF
TI  - Optimizing decision making in concolic execution using reinforcement learning
T2  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
SP  - 52
EP  - 61
AU  - C. Paduraru
AU  - M. Paduraru
AU  - A. Stefanescu
PY  - 2020
DO  - 10.1109/ICSTW50294.2020.00025
JO  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)
Y1  - 24-28 Oct. 2020
AB  - This paper presents an improvement to a new opensource testing tool capable of performing concolic execution on x86 binaries. The novelty is to use a reinforcement learning solution that reduces the number of symbolically executed states. It does so by learning a set of models that predict how efficiently it would be to change the conditions at various branch points. Thus, we first reinterpret the state-of-the-art concolic execution algorithm as a typical reinforcement learning environment, then we build estimation models used to prune states that do not look promising. The architecture of the base model is a Deep Q-Network used inside an LSTM that captures the patterns from the ordered set of branch points (path) resulted by executing the application under test with different inputs generated at runtime (experiments). Various reward functions can give automatic feedback from the concolic execution environment to define different policies. These are customizable in our open-source implementation, such that users can define their custom test targets.
ER  - 

TY  - CONF
TI  - A Novel approach of GUI Mapping with image based widget detection and classification
T2  - 2021 2nd International Conference on Intelligent Engineering and Management (ICIEM)
SP  - 342
EP  - 346
AU  - K. Jaganeshwari
AU  - S. Djodilatchoumy
PY  - 2021
DO  - 10.1109/ICIEM51511.2021.9445281
JO  - 2021 2nd International Conference on Intelligent Engineering and Management (ICIEM)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 2nd International Conference on Intelligent Engineering and Management (ICIEM)
Y1  - 28-30 April 2021
AB  - Software testing is vital for the intellectual benefits of software reliability and quality. At present, Graphical user interfaces are the most common and widely used interfaces in the software industry. Furthermore, GUI Testing is an important approach to ensure the quality of software. Automated software testing is a GUI front end applications similar to APP, and WEB, etc and is a vastly time and resource-consuming task. Therefore, this will become even more complex in rapidly updated GUI applications such as Ex: Patches/Version updates of a mobile App, or the product and offer updates in marketing websites like Flipkart, Amazon, etc., in which the GUI components are continuously updated infinitely. Developing a test case scenario whenever a new GUI component is updated will affect the productivity of the application. In our experiment, we found a better way of improving GUI testing by consequently detecting and classifying GUI widgets using machine learning techniques. Additionally, we also found that detecting and classifying GUI objects in screenshots and reports with a position of the widgets (x, y coordinates) and type of the widgets, matches with trained samples, URL links, and screen links. Hence, we in this paper will analyze and devise an efficient automated testing strategy for Web Applications. This is a unique way of web Graphical user interface testing with a computer vision. This paper will also present the parameters used for object detection, classification, and evaluation with image processing using machine learning algorithms with better accuracy.
ER  - 

