TY  - CONF
TI  - Attribute Rule performance in Data Mining for Software Deformity Prophecy Datasets Models
T2  - 2019 International Conference on Advances in the Emerging Computing Technologies (AECT)
SP  - 1
EP  - 6
AU  - S. Shaikh
AU  - L. Changan
AU  - M. R. Malik
PY  - 2020
DO  - 10.1109/AECT47998.2020.9194187
JO  - 2019 International Conference on Advances in the Emerging Computing Technologies (AECT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2019 International Conference on Advances in the Emerging Computing Technologies (AECT)
Y1  - 10-10 Feb. 2020
AB  - In recently, all the developers, programmer and software engineers, they are working specially on software component and software testing to compete the software technology in the world. For this competition, they are using different kind of sources to analysis the software reliability and importance. Nowadays Data mining is one of source, which is used in software for overcome the problem of software fault which occur during the software test and its analysis. This kind of problem leads software deformity prophecy in software. In this research paper, we are also trying to overcome the software deformity prophecy problem with the help of our proposed solution called ONER rule attribute. We have used REPOSITORY datasets models, these datasets models are defected and non-defected datasets models. Our analysis class of interest is defected models. In our research, we have analyzed the efficiency of our proposed solution methods. The experiments results showed that using of ONER with discretize, have improved the efficiency of correctly classified instances in all. Using percentage split and training datasets with ONER discretize rule attribute have improved correctly classified in all datasets models. The analysis of positive accuracy f-measure is also increased in percentage split during the use of ONER with discretize but in some datasets models, the training data and cross validation is better with use of ONER rule attribute. The area under curve (ROC) in both scenarios using ONER rule attribute and discretize with ONER rule attribute is almost same or equal with each other.
ER  - 

TY  - CONF
TI  - Empirical Analysis of Artificial Immune System Algorithms for Aging Related Bug Prediction
T2  - 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS)
SP  - 692
EP  - 697
AU  - M. Khanna
AU  - M. Aggarwal
AU  - N. Singhal
PY  - 2021
DO  - 10.1109/ICACCS51430.2021.9441809
JO  - 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS)
IS  - 
SN  - 2575-7288
VO  - 1
VL  - 1
JA  - 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS)
Y1  - 19-20 March 2021
AB  - The complex nature of human immunology algorithms has motivated the research community to explore their practical applications in various other fields. As a result, Artificial Immune Systems (AISs) is one such class of algorithms that has found its way into software quality predictive modeling. In this paper, we evaluate AIS algorithms for developing Aging-Related Bug (ARB) prediction models. Software Aging, the gradual degradation and resource exhaustion in software systems, is said to be caused by ARBs, which may or may not be identified during software testing. Therefore, predicting ARBs before software release can help software managers in reducing their impact. This paper presents an empirical study that statistically analyzes the effectiveness of AIS classifiers for ARB prediction on five open-source software datasets. In order to account for the imbalanced nature of the investigated datasets, we used resampling and cost-sensitive classifiers. The results of the study indicate the effectiveness of AIS algorithms for developing ARB prediction models.
ER  - 

TY  - CONF
TI  - Automated Personalized Feedback in Introductory Java Programming MOOCs
T2  - 2017 IEEE 33rd International Conference on Data Engineering (ICDE)
SP  - 1259
EP  - 1270
AU  - V. J. Marin
AU  - T. Pereira
AU  - S. Sridharan
AU  - C. R. Rivero
PY  - 2017
DO  - 10.1109/ICDE.2017.169
JO  - 2017 IEEE 33rd International Conference on Data Engineering (ICDE)
IS  - 
SN  - 2375-026X
VO  - 
VL  - 
JA  - 2017 IEEE 33rd International Conference on Data Engineering (ICDE)
Y1  - 19-22 April 2017
AB  - Currently, there is a "boom" in introductory programming courses to help students develop their computational thinking skills. Providing timely, personalized feedback that makes students reflect about what and why they did correctly or incorrectly is critical in such courses. However, the limited number of instructors and the great volume of submissions instructors need to assess, especially in Massive Open Online Courses (MOOCs), prove this task a challenge. One solution is to hire graders or create peer discussions among students, however, feedback may be too general, incomplete or even incorrect. Automatic techniques focus on: a) Functional testing, in which feedback usually does not sufficiently guide novices, b) Software verification to find code bugs, which may confuse novices since these tools usually skip true errors or produce false errors, and c) Comparing using reference solutions, in which a large amount of reference solutions or pre-existing correct submissions are usually required. This paper presents a semantic-aware technique to provide personalized feedback that aims to mimic an instructor looking for code snippets in student submissions. These snippets are modeled as subgraph patterns with natural language feedback attached to them. Submissions are transformed into extended program dependence graphs combining control and data flows. We leverage subgraph matching techniques to compute the adequate personalized feedback. Also, constraints correlating patterns allow performing fine-grained assessments. We have evaluated our method on several introductory programming assignments and a large number of submissions. Our technique delivered personalized feedback in milliseconds using a small set of patterns, which makes it appealing in real-world settings.
ER  - 

TY  - CONF
TI  - Concepts in Testing of Autonomous Systems: Academic Literature and Industry Practice
T2  - 2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)
SP  - 74
EP  - 81
AU  - Q. Song
AU  - E. Engström
AU  - P. Runeson
PY  - 2021
DO  - 10.1109/WAIN52551.2021.00018
JO  - 2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)
Y1  - 30-31 May 2021
AB  - Testing of autonomous systems is extremely important as many of them are both safety-critical and security-critical. The architecture and mechanism of such systems are fundamentally different from traditional control software, which appears to operate in more structured environments and are explicitly instructed according to the system design and implementation. To gain a better understanding of autonomous systems practice and facilitate research on testing of such systems, we conducted an exploratory study by synthesizing academic literature with a focus group discussion and interviews with industry practitioners. Based on thematic analysis of the data, we provide a conceptualization of autonomous systems, classifications of challenges and current practices as well as of available techniques and approaches for testing of autonomous systems. Our findings also indicate that more research efforts are required for testing of autonomous systems to improve both the quality and safety aspects of such systems.
ER  - 

TY  - CONF
TI  - Critical data leak analysis in educational environment
T2  - 2016 4th International Conference on Cyber and IT Service Management
SP  - 1
EP  - 6
AU  - I. M. A. G. Azmi
AU  - Q. M. Ashraf
AU  - S. Zulhuda
AU  - M. B. Daud
PY  - 2016
DO  - 10.1109/CITSM.2016.7577523
JO  - 2016 4th International Conference on Cyber and IT Service Management
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 4th International Conference on Cyber and IT Service Management
Y1  - 26-27 April 2016
AB  - The rapid growth of computer technologies has resulted in a corresponding increase in the creation of new loopholes in systems which eventually might result in data leak. Data leakage is an incident in which sensitive information is released to any unauthorized party intentionally or unintentionally. There is a large set of software available which can be used to prevent data leak, however they fail to cover all the channels of leakage involved. Many institutions specifically educational institutions are in possession of large amounts of personal data. Due to the sheer size of these institutions, securing each and every system is overlooked. Educational institutions need to implement higher levels of security practices in their systems to stop any attempts of users trying to access critical data intentionally. If adequate measures are not taken, records belonging to the staff as well as students can be manipulated and used. We conduct a case study, and show the potential weaknesses and vulnerabilities that can exist in an educational environment which can be a path for data leak. The results have important implications on preventive measures that can be used by such institutions to avert data leak.
ER  - 

TY  - JOUR
TI  - Large Scale Evaluation of Natural Language Processing Based Test-to-Code Traceability Approaches
T2  - IEEE Access
SP  - 79089
EP  - 79104
AU  - A. Kicsi
AU  - V. Csuvik
AU  - L. Vidács
PY  - 2021
DO  - 10.1109/ACCESS.2021.3083923
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 9
VL  - 9
JA  - IEEE Access
Y1  - 2021
AB  - Traceability information can be crucial for software maintenance, testing, automatic program repair, and various other software engineering tasks. Customarily, a vast amount of test code is created for systems to maintain and improve software quality. Today's test systems may contain tens of thousands of tests. Finding the parts of code tested by each test case is usually a difficult and time-consuming task without the help of the authors of the tests or at least clear naming conventions. Recent test-to-code traceability research has employed various approaches but textual methods as standalone techniques were investigated only marginally. The naming convention approach is a well-regarded method among developers. Besides their often only voluntary use, however, one of its main weaknesses is that it can only identify one-to-one links. With the use of more versatile text-based methods, candidates could be ranked by similarity, thus producing a number of possible connections. Textual methods also have their disadvantages, even machine learning techniques can only provide semantically connected links from the text itself, these can be refined with the incorporation of structural information. In this paper, we investigate the applicability of three text-based methods both as a standalone traceability link recovery technique and regarding their combination possibilities with each other and with naming conventions. The paper presents an extensive evaluation of these techniques using several source code representations and meta-parameter settings on eight real, medium-sized software systems with a combined size of over 1.25 million lines of code. Our results suggest that with suitable settings, text-based approaches can be used for test-to-code traceability purposes, even where naming conventions were not followed.
ER  - 

TY  - JOUR
TI  - Mining Fix Patterns for FindBugs Violations
T2  - IEEE Transactions on Software Engineering
SP  - 165
EP  - 188
AU  - K. Liu
AU  - D. Kim
AU  - T. F. Bissyandé
AU  - S. Yoo
AU  - Y. Le Traon
PY  - 2021
DO  - 10.1109/TSE.2018.2884955
JO  - IEEE Transactions on Software Engineering
IS  - 1
SN  - 1939-3520
VO  - 47
VL  - 47
JA  - IEEE Transactions on Software Engineering
Y1  - 1 Jan. 2021
AB  - Several static analysis tools, such as Splint or FindBugs, have been proposed to the software development community to help detect security vulnerabilities or bad programming practices. However, the adoption of these tools is hindered by their high false positive rates. If the false positive rate is too high, developers may get acclimated to violation reports from these tools, causing concrete and severe bugs being overlooked. Fortunately, some violations are actually addressed and resolved by developers. We claim that those violations that are recurrently fixed are likely to be true positives, and an automated approach can learn to repair similar unseen violations. However, there is lack of a systematic way to investigate the distributions on existing violations and fixed ones in the wild, that can provide insights into prioritizing violations for developers, and an effective way to mine code and fix patterns which can help developers easily understand the reasons of leading violations and how to fix them. In this paper, we first collect and track a large number of fixed and unfixed violations across revisions of software. The empirical analyses reveal that there are discrepancies in the distributions of violations that are detected and those that are fixed, in terms of occurrences, spread and categories, which can provide insights into prioritizing violations. To automatically identify patterns in violations and their fixes, we propose an approach that utilizes convolutional neural networks to learn features and clustering to regroup similar instances. We then evaluate the usefulness of the identified fix patterns by applying them to unfixed violations. The results show that developers will accept and merge a majority (69/116) of fixes generated from the inferred fix patterns. It is also noteworthy that the yielded patterns are applicable to four real bugs in the Defects4J major benchmark for software testing and automated repair.
ER  - 

TY  - CONF
TI  - Characterizing Defective Configuration Scripts Used for Continuous Deployment
T2  - 2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)
SP  - 34
EP  - 45
AU  - A. Rahman
AU  - L. Williams
PY  - 2018
DO  - 10.1109/ICST.2018.00014
JO  - 2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)
Y1  - 9-13 April 2018
AB  - In software engineering, validation and verification (V&V) resources are limited and characterization of defective software source files can help in efficiently allocating V&V resources. Similar to software source files, defects occur in the scripts used to automatically manage configurations and software deployment infrastructure, often known as infrastructure as code (IaC) scripts. Defects in IaC scripts can have dire consequences, for example, creating large-scale system outages. Identifying the characteristics of defective IaC scripts can help in mitigating these defects by allocating V&V efforts efficiently based upon these characteristics. The objective of this paper is to help software practitioners to prioritize validation and verification efforts for infrastructure as code (IaC) scripts by identifying the characteristics of defective IaC scripts. Researchers have previously extracted text features to characterize defective software source files written in general purpose programming languages. We investigate if text features can be used to identify properties that characterize defective IaC scripts. We use two text mining techniques to extract text features from IaC scripts: the bag-of-words technique, and the term frequency-inverse document frequency (TF-IDF) technique. Using the extracted features and applying grounded theory, we characterize defective IaC scripts. We also use the text features to build defect prediction models with tuned statistical learners. We mine open source repositories from Mozilla, Openstack, and Wikimedia Commons, to construct three case studies and evaluate our methodology. We identify three properties that characterize defective IaC scripts: filesystem operations, infrastructure provisioning, and managing user accounts. Using the bag-of-word technique, we observe a median F-Measure of 0.74, 0.71, and 0.73, respectively, for Mozilla, Openstack, and Wikimedia Commons. Using the TF-IDF technique, we observe a median F-Measure of 0.72, 0.74, and 0.70, respectively, for Mozilla, Openstack, and Wikimedia Commons.
ER  - 

TY  - JOUR
TI  - Successful Engagement of Practitioners and Software Engineering Researchers: Evidence From 26 International Industry–Academia Collaborative Projects
T2  - IEEE Software
SP  - 65
EP  - 75
AU  - V. Garousi
AU  - D. C. Shepherd
AU  - K. Herkiloglu
PY  - 2020
DO  - 10.1109/MS.2019.2914663
JO  - IEEE Software
IS  - 6
SN  - 1937-4194
VO  - 37
VL  - 37
JA  - IEEE Software
Y1  - Nov.-Dec. 2020
AB  - There has been a push to increase the practical relevance and impact of software engineering research. Although many practitioners and researchers agree that this change is desirable, thus far, only a few concrete actions have been taken by the community. In this article, we present our experiences with a large number of collaborative research projects that have had a practical (industrial) impact.
ER  - 

TY  - JOUR
TI  - Combinatorial Test Suites Generation Strategy Utilizing the Whale Optimization Algorithm
T2  - IEEE Access
SP  - 192288
EP  - 192303
AU  - A. A. Hassan
AU  - S. Abdullah
AU  - K. Z. Zamli
AU  - R. Razali
PY  - 2020
DO  - 10.1109/ACCESS.2020.3032851
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 8
VL  - 8
JA  - IEEE Access
Y1  - 2020
AB  - The potentially many software system input combinations make exhaustive testing practically impossible. To address this issue, combinatorial t-way testing (where t indicates the interaction strength, i.e. the number of interacting parameters (input)) was adopted to minimize the number of cases for testing. Complimentary to existing testing techniques (e.g. boundary value, equivalence partitioning, cause and effect graphing), combinatorial testing helps to detect faults caused by the faulty interaction between input parameters. In the last 15 years, applications of meta-heuristics as the backbone of t-way test suite generation have shown promising results (e.g. Particle Swarm Optimization, Cuckoo Search, Flower Pollination Algorithm, and Hyper-Heuristics (HHH), to name a few). Supporting the No Free Lunch theorem, as well as potentially offering new insights into the whole process of t-way generation, this article proposes a new strategy with constraint support based on the Whale Optimization Algorithm (WOA). Our work is the first attempt to adopt the WOA as part of a search-based software engineering (SBSE) initiative for t-way test suite generation with constraint support. The experimental results of the test-suite generation indicate that WOA produces competitive outcomes compared to some selected single-based and population-based meta-heuristic algorithms.
ER  - 

TY  - JOUR
TI  - Detecting Software Security Vulnerabilities Via Requirements Dependency Analysis
T2  - IEEE Transactions on Software Engineering
SP  - 1665
EP  - 1675
AU  - W. Wang
AU  - F. Dumont
AU  - N. Niu
AU  - G. Horton
PY  - 2022
DO  - 10.1109/TSE.2020.3030745
JO  - IEEE Transactions on Software Engineering
IS  - 5
SN  - 1939-3520
VO  - 48
VL  - 48
JA  - IEEE Transactions on Software Engineering
Y1  - 1 May 2022
AB  - Cyber attacks targeting software applications have a tremendous impact on our daily life. For example, attackers have utilized vulnerabilities of web applications to steal and gain unauthorized use of sensitive data stored in these systems. Previous studies indicate that security testing is highly precise, and therefore is widely applied to validate individual security requirements. However, dependencies between security requirements may cause additional vulnerabilities. Manual dependency detection faces scalability challenges, e.g., a previous study shows that the pairwise dependency analysis of 40 requirements would take around 12 hours. In this article, we present a novel approach which integrates the interdependency among high-level security requirements, such as those documented in policies, regulations, and standards. We then use automated requirements tracing methods to identify product-level security requirements and their dependencies. Our manual analysis of HIPAA and FIPS 200 leads to the identification of five types of high-level security requirements dependencies, which further inform the automated tracing methods and guide the designs of system-level security tests. Experimental results on five projects in healthcare and education domains show the significant recall improvements at 81 percent. Our case study on a deployed production system uncovers four previously unknown vulnerabilities by using the detected requirements dependencies as test paths, demonstrating our approach's value in connecting requirements engineering with security testing.
ER  - 

TY  - JOUR
TI  - RAPD: Rapid and Participatory Application Development of Usable Systems During COVID19 Crisis
T2  - IEEE Access
SP  - 93601
EP  - 93614
AU  - Y. -A. Daraghmi
AU  - E. -Y. Daraghmi
PY  - 2022
DO  - 10.1109/ACCESS.2022.3203582
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 10
VL  - 10
JA  - IEEE Access
Y1  - 2022
AB  - Software development methods have been evolved to enable producing usable systems rapidly while considering all requirements. Several studies have focused on the need to balance between rapid development and capturing requirements related to user experience and business workflow. This balance has become more urging during COVID19 because many businesses want to quickly transfer to usable electronic systems that are accurate, efficient, easy to learn, satisfy users and support remote work. Therefore, this paper proposes a framework by integrating Rapid Application Development (RAD) method with Participatory Design (PD) method for enabling rapid production of usable systems. Both RAD and PD consist of design stages that can overlap and generate new phases where users participate in the design process and accelerate the production. Five usability tests are also added to the framework to validate the usability of the design at all stages. The Action Research method is used to assess the framework empirically in a context of an urgent need to an electronic system, and qualitative data analyses were conducted. The results show that the framework can be adopted by software companies because it satisfies the requirements of adopting software development methods. Also, the system developed using the framework is usable. The paper concludes that COVID19 affects software development by emphasizing rapid development while maintaining workflow. Also, using video conference for remote design assists in meeting users more frequently and in creating concise requirement documentation.
ER  - 

TY  - CONF
TI  - An Improvement of a Checkpoint-based Distributed Testing Technique on a Big Data Environment
T2  - 2019 21st International Conference on Advanced Communication Technology (ICACT)
SP  - 1081
EP  - 1090
AU  - B. Sudsee
AU  - C. Kaewkasi
PY  - 2019
DO  - 10.23919/ICACT.2019.8702037
JO  - 2019 21st International Conference on Advanced Communication Technology (ICACT)
IS  - 
SN  - 1738-9445
VO  - 
VL  - 
JA  - 2019 21st International Conference on Advanced Communication Technology (ICACT)
Y1  - 17-20 Feb. 2019
AB  - The advancement of storage technologies and the fast-growing number of generated data have made the world moved into the Big Data era. In this past, we had many data mining tools but they are inadequate to process Data-Intensive Scalable Computing workloads. The Apache Spark framework is a popular tool designed for Big Data processing. It leverages in-memory processing techniques that make Spark up to 100 times faster than Hadoop. Testing this kind of Big Data program is time consuming. Unfortunately, developers lack a proper testing framework, which cloud help assure quality of their data-intensive processing programs while saving development time and storage usages.We propose Distributed Test Checkpointing (DTC) for Apache Spark. DTC applies unit testing to the Big Data software development life cycle and reduce time spent for each testing loop with checkpoint. By using checkpoint technique, DTC keeps quality of Big Data processing software while keeps an inexpensive testing cost by overriding original Spark mechanism so that developers no pain to learn how to use DTC. Moreover, DTC has no addition abstraction layers. Developers can upgrade to a new version of Spark seamlessly. From the experimental results, we found that in the subsequence rounds of unit testing, DTC dramatically speed the testing time up to 450-500% faster. In case of storage, DTC can cut unnecessary data off and make the storage 19.7 times saver than the original checkpoint of Spark. DTC can be used either in case of JVM termination or testing with random values.
ER  - 

TY  - JOUR
TI  - A Survey of App Store Analysis for Software Engineering
T2  - IEEE Transactions on Software Engineering
SP  - 817
EP  - 847
AU  - W. Martin
AU  - F. Sarro
AU  - Y. Jia
AU  - Y. Zhang
AU  - M. Harman
PY  - 2017
DO  - 10.1109/TSE.2016.2630689
JO  - IEEE Transactions on Software Engineering
IS  - 9
SN  - 1939-3520
VO  - 43
VL  - 43
JA  - IEEE Transactions on Software Engineering
Y1  - 1 Sept. 2017
AB  - App Store Analysis studies information about applications obtained from app stores. App stores provide a wealth of information derived from users that would not exist had the applications been distributed via previous software deployment methods. App Store Analysis combines this non-technical information with technical information to learn trends and behaviours within these forms of software repositories. Findings from App Store Analysis have a direct and actionable impact on the software teams that develop software for app stores, and have led to techniques for requirements engineering, release planning, software design, security and testing. This survey describes and compares the areas of research that have been explored thus far, drawing out common aspects, trends and directions future research should take to address open problems and challenges.
ER  - 

TY  - CONF
TI  - [Title page]
T2  - 2015 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)
SP  - 1
EP  - 1
PY  - 2015
DO  - 10.1109/TALE.2015.7385997
JO  - 2015 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2015 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)
Y1  - 10-12 Dec. 2015
AB  - The following topics are dealt with: teaching-assessment-and-learning-for-engineering; mobile learning; engineering education; computer programming course; software testing skills teaching; higher education; e-learning environment; online educational resources; semisupervised learning approach; MOOC; m-learning; STEM; and telecommunication engineering.
ER  - 

TY  - CONF
TI  - [Title page]
T2  - 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE)
SP  - 1
EP  - 1
PY  - 2015
DO  - 10.1109/ABLAZE.2015.7155050
JO  - 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE)
Y1  - 25-27 Feb. 2015
AB  - The following topics are dealt with: vibration signal based monitoring; mechanical microdrilling; rule based inflectional urdu stemmer usal; rule based derivational urdu stemmer usal; fuzzy logic controller; heat exchanger temperature process; text dependent speaker recognition; MFCC; SBC; multikeyword based sorted querying; encrypted cloud data; communication understandability enhancement; GSD; parsing; input power quality; switched reluctance motor drive; externally powered upper limb prostheses; program test data generation; launch vehicle optimal trajectory generation; misalignment fault detection; induction motors; current signature analysis; vibration signature analysis; wind power plants; vortex induced vibration; mechanical structure modal analysis; machining parameter optimization; diesel engines; high speed nonvolatile NEMS memory devices; image fusion; RGB color space; LUV color space; offline English character recognition; human skin detection; tumor boundary extraction; MR images; OdiaBraille; text transcription; shadow detection; YIQ color models; color aerial images; moving object segmentation; image data deduplication; iris recognition; two-stage series connected thermoelectric generator; education information system; cyclone separator CFD simulation; imperfect debugging; vulnerability discovery model; stochastic differential equation; cloud data access; attribute based encryption; agile SCRUM framework; PID controller optimisation; hybrid watermarking technique; privacy preservation; vertical partitioned medical database; power amplifier; software reliability growth modeling; cochlear implantation; cellular towers; feedforward neural networks; MBSOM; agent based semantic ontology matching; phonetic word identification; test case selection; MANET security issues; online movie data classification; modified LEACH protocol; mobile ad hoc networks; virtual machine introspection; task scheduling; cluster computing; image compression; green cloud computing; critical health data transmission system; irreversible regenerative Brayton cycle; task set based adaptive round robin scheduling; database security; heterogeneous online social networks; aspect oriented systems; IP network; MPLS network; DBSCAN algorithm; VANET; self-organizing feature map; image segmentation; enzyme classification; wireless sensor networks; energy smart routing protocol; adaptive gateway discovery mechanism; heuristic job scheduling; AODV based congestion control protocol; expert system; home appliances; relay node based heer protocol; data storage; TORA security; data aggregation; low energy adaptive stable energy efficient protocol; fuzzy logic based clustering algorithm; hybrid evolutionary MPLS tunneling algorithm; English mobile teaching; eigenvector centrality; genetic algorithms; data mining; heart disease prediction; lossless data compression; reconfigurable ring resonator; triple band stacked patch antenna; energy based spectrum sensing; cognitive radio networks; FPGA; knowledge representation; multiband microstrip antenna; Web indexing; HTML priority system; Web cache recommender system; e-learning; IT skill learning for visual impaired; user review data analysis; software up-gradation model; software testing; Web crawlers; secret key watermarking; WAV audio file; SRM drive; ZETA converter; fractional PID tuning; medical image reconstruction; speech recognition system; video authentication; digital forensics; content based image retrieval; image classification; hybrid wavelet transform; facial feature extraction; RBSD adder; smart home environment; generalized discrete time model; We Chat marketing; foreign language learning; carbon dioxide emission mitigation; power generation; smartphone storage enhancement; and virtualization.
ER  - 

TY  - CONF
TI  - [Front cover]
T2  - 2015 International Computer Science and Engineering Conference (ICSEC)
SP  - 1
EP  - 1
PY  - 2015
DO  - 10.1109/ICSEC.2015.7401457
JO  - 2015 International Computer Science and Engineering Conference (ICSEC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2015 International Computer Science and Engineering Conference (ICSEC)
Y1  - 23-26 Nov. 2015
AB  - The following topics are dealt with: robot; electronic health information; parser generator; high-frequency-queries-based filter; health GIS system; Big Data cloud computing; word segmentation technique; flood forecasting; Java teaching; human leukocyte antigen gene prediction; wireless sensor network; P2P traffic classification; stereo image matching method; LTE; satellite communications; software development projects; software testing; sentiment analysis; emotion recognition; MPI-PageRank; and soccer archive summarization.
ER  - 

TY  - CONF
TI  - Table of contents
T2  - 2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Technologies Results Track (ICSE-NIER)
SP  - v
EP  - vi
PY  - 2017
DO  - 10.1109/ICSE-NIER.2017.4
JO  - 2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Technologies Results Track (ICSE-NIER)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Technologies Results Track (ICSE-NIER)
Y1  - 20-28 May 2017
AB  - The following topics are dealt with: software engineering; software testing; software development; program synthesis; program analysis; data mining; learning; and monitoring.
ER  - 

TY  - CONF
TI  - Table of contents
T2  - 2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)
SP  - xi
EP  - xvi
PY  - 2017
DO  - 10.1109/SNPD.2017.8022643
JO  - 2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)
Y1  - 26-28 June 2017
AB  - The following topics are dealt with: artificial intelligence; audio and video technology; communication system and networks; component-based software engineering; cryptography and network security; data mining; machine learning; database system management; e-commerce; image, speech, and signal processing; Internet technology; ad-hoc networks; parallel processing; software specification and architecture; software testing; Web-based applications; information systems; ergonomics; and evolutionary computation.
ER  - 

